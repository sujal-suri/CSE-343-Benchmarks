
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# JointMatch for Freesound Audio Tagging\n",
    "\n",
    "This notebook implements the JointMatch algorithm for semi-supervised audio classification on the Freesound dataset. It adapts the structure from a previous EPASS implementation and incorporates the key concepts of JointMatch:\n",
    "\n",
    "1.  **Adaptive Local Thresholding:** Dynamically adjusts confidence thresholds for pseudo-labeling based on class learning status.\n",
    "2.  **Cross-Labeling:** Utilizes two differently initialized models that teach each other.\n",
    "3.  **Weighted Disagreement & Agreement Update:** Weights the unsupervised loss to prioritize disagreement samples, maintaining model diversity while still leveraging agreement samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e807f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f2b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Configuration\n",
    "# ----------------------------\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Audio & Spectrogram Params\n",
    "        self.sr = 32000           # Audio sample rate\n",
    "        self.duration = 5         # Audio duration (seconds)\n",
    "        self.n_mels = 128         # Number of Mel bands\n",
    "        \n",
    "        # Training Params\n",
    "        self.batch_size = 16      # Combined batch size (adjust per GPU memory)\n",
    "        self.epochs = 30           # Number of epochs (adjust as needed)\n",
    "        self.lr = 1e-4            # Learning rate\n",
    "        self.num_classes = 41     # Number of classes (as per train.csv)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Semi-Supervised Params\n",
    "        self.num_labeled_per_class = 25 # Number of labeled samples per class\n",
    "        self.mu = 7               # Ratio of unlabeled to labeled samples per batch (unlabeled_bs = mu * labeled_bs)\n",
    "        self.wu = 1.0             # Unsupervised loss weight\n",
    "        self.threshold = 0.95     # Base confidence threshold (tau)\n",
    "        self.ema_decay = 0.999    # EMA decay rate (lambda)\n",
    "        self.delta = 0.8          # Disagreement weight (delta > 0.5 gives more weight to disagreement)\n",
    "        \n",
    "        # SpecAugment Params (for strong augmentation)\n",
    "        self.freq_mask_param = 27\n",
    "        self.time_mask_param = 70 # Adjusted based on spectrogram width\n",
    "        \n",
    "        # Model Saving\n",
    "        self.model_save_path_f = \"best_model_f.pth\"\n",
    "        self.model_save_path_g = \"best_model_g.pth\"\n",
    "        \n",
    "        # Calculated params\n",
    "        self.labeled_batch_size = self.batch_size // (self.mu + 1)\n",
    "        self.unlabeled_batch_size = self.batch_size - self.labeled_batch_size\n",
    "        \n",
    "        # Data paths (update if necessary)\n",
    "        self.train_csv_path = \"../input/freesound-audio-tagging/train.csv\"\n",
    "        self.test_csv_path = \"../input/freesound-audio-tagging/test_post_competition.csv\"\n",
    "        self.audio_train_dir = \"../input/freesound-audio-tagging/audio_train/\"\n",
    "        self.audio_test_dir  = \"../input/freesound-audio-tagging/audio_test/\"\n",
    "\n",
    "\n",
    "config = Config()\n",
    "print(f\"Device: {config.device}\")\n",
    "print(f\"Labeled Batch Size: {config.labeled_batch_size}\")\n",
    "print(f\"Unlabeled Batch Size: {config.unlabeled_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e6393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Audio Preprocessing Function\n",
    "# ----------------------------\n",
    "def preprocess_audio(path, sr=config.sr, duration=config.duration, n_mels=config.n_mels):\n",
    "    try:\n",
    "        y, _ = librosa.load(path, sr=sr)\n",
    "        max_len = sr * duration\n",
    "        # Pad or truncate to fixed length\n",
    "        if len(y) < max_len:\n",
    "            y = np.pad(y, (0, max_len - len(y)))\n",
    "        else:\n",
    "            y = y[:max_len]\n",
    "        # Compute mel spectrogram\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        # Normalize to [0, 1]\n",
    "        mel_min = mel_db.min()\n",
    "        mel_max = mel_db.max()\n",
    "        if mel_max == mel_min: # Avoid division by zero for silent clips\n",
    "             return np.zeros_like(mel_db, dtype=np.float32)\n",
    "        mel_norm = (mel_db - mel_min) / (mel_max - mel_min)\n",
    "        return mel_norm.astype(np.float32)  # shape: (n_mels, time)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "        # Return a zero array or handle error appropriately\n",
    "        time_steps = int(sr * duration * (1 / 512)) +1 # Approximate time steps from hop_length=512\n",
    "        return np.zeros((n_mels, time_steps), dtype=np.float32)"
   ]
  },
   {
   "cell_type": "markdown",
   "id": "aug-md",
   "metadata": {},
   "source": [
    "### 2.1 Augmentation Functions\n",
    "\n",
    "- **Weak Augmentation:** Identity (no change) or very mild noise could be used. For simplicity, we use Identity here.\n",
    "- **Strong Augmentation:** SpecAugment (frequency and time masking on the Mel spectrogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augmentations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2.1 Augmentation Functions\n",
    "# ----------------------------\n",
    "\n",
    "# Weak augmentation (identity for simplicity)\n",
    "def weak_augment(mel_spec):\n",
    "    return torch.tensor(mel_spec).unsqueeze(0) # Add channel dim\n",
    "\n",
    "# Strong augmentation (SpecAugment)\n",
    "spec_augment = torchaudio.transforms.SpecAugment(\n",
    "    freq_masking_param=config.freq_mask_param,\n",
    "    time_masking_param=config.time_mask_param\n",
    ")\n",
    "\n",
    "def strong_augment(mel_spec):\n",
    "    mel_tensor = torch.tensor(mel_spec).unsqueeze(0) # Add channel dim\n",
    "    augmented_mel = spec_augment(mel_tensor)\n",
    "    return augmented_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711ec98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Dataset Classes\n",
    "# ----------------------------\n",
    "\n",
    "# Dataset for Labeled Data\n",
    "class FreesoundLabeledDataset(Dataset):\n",
    "    def __init__(self, df, audio_dir, label_map, transform=preprocess_audio, augment=weak_augment):\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.label_map = label_map\n",
    "        self.transform = transform\n",
    "        self.augment = augment # Only weak augmentation needed for supervised loss\n",
    "        self.fnames = df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        file_path = os.path.join(self.audio_dir, fname)\n",
    "        mel = self.transform(file_path)\n",
    "        mel_tensor_aug = self.augment(mel) # (1, n_mels, time)\n",
    "        label = self.label_map[self.df.loc[fname, 'label']]\n",
    "        return mel_tensor_aug, torch.tensor(label)\n",
    "\n",
    "# Dataset for Unlabeled Data\n",
    "class FreesoundUnlabeledDataset(Dataset):\n",
    "    def __init__(self, df, audio_dir, label_map, transform=preprocess_audio, weak_aug=weak_augment, strong_aug=strong_augment):\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.label_map = label_map # Keep label map for potential analysis, but don't return label\n",
    "        self.transform = transform\n",
    "        self.weak_aug = weak_aug\n",
    "        self.strong_aug = strong_aug\n",
    "        self.fnames = df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        file_path = os.path.join(self.audio_dir, fname)\n",
    "        mel = self.transform(file_path)\n",
    "        mel_tensor_weak = self.weak_aug(mel)     # (1, n_mels, time)\n",
    "        mel_tensor_strong = self.strong_aug(mel) # (1, n_mels, time)\n",
    "        # We don't return the true label for unlabeled data during training\n",
    "        return mel_tensor_weak, mel_tensor_strong\n",
    "\n",
    "# Dataset for Testing (uses weak augmentation/no augmentation)\n",
    "class FreesoundTestDataset(Dataset):\n",
    "    def __init__(self, df, audio_dir, label_map, transform=preprocess_audio, augment=weak_augment):\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.label_map = label_map\n",
    "        self.transform = transform\n",
    "        self.augment = augment # Use weak/no augment for eval consistency\n",
    "        self.fnames = df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        file_path = os.path.join(self.audio_dir, fname)\n",
    "        mel = self.transform(file_path)\n",
    "        mel_tensor = self.augment(mel) # (1, n_mels, time)\n",
    "        label = self.label_map[self.df.loc[fname, 'label']]\n",
    "        return mel_tensor, torch.tensor(label)"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "metadata-md",
   "metadata": {},
   "source": [
    "### 4. Prepare Metadata, Label Map, and Data Splits\n",
    "\n",
    "- Load `train.csv` and `test_post_competition.csv`.\n",
    "- Create the label map.\n",
    "- **Crucially**, split the original `train.csv` data into a small labeled set (`labeled_df`) and a larger unlabeled set (`unlabeled_df`) using stratified sampling to preserve class distribution in the labeled set.\n",
    "- Create a separate validation set from the *original* training data (before splitting into labeled/unlabeled) for unbiased evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce985d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Prepare Metadata, Label Map, and Data Splits\n",
    "# ----------------------------\n",
    "# Load training CSV\n",
    "train_df_full = pd.read_csv(config.train_csv_path)\n",
    "train_df_full.set_index(\"fname\", inplace=True)\n",
    "\n",
    "# Load test CSV (evaluation set with ground-truth labels)\n",
    "test_df = pd.read_csv(config.test_csv_path)\n",
    "test_df = test_df.dropna(subset=['label'])  # Filter out rows with missing labels\n",
    "test_df.set_index(\"fname\", inplace=True)\n",
    "\n",
    "# Create label mapping (alphabetical order)\n",
    "labels = sorted(train_df_full['label'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "config.num_classes = len(labels) # Update num_classes based on actual data\n",
    "print(f\"Number of classes: {config.num_classes}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# --- Semi-Supervised Split ---\n",
    "# Stratified split to get a small labeled set and a validation set\n",
    "train_val_df, unlabeled_df = train_test_split(\n",
    "    train_df_full,\n",
    "    train_size=config.num_labeled_per_class * config.num_classes, # Total labeled samples\n",
    "    stratify=train_df_full['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Further split train_val_df into labeled and validation\n",
    "# Use a portion for validation, the rest strictly as labeled training data\n",
    "# Let's use a fixed validation split for simplicity (e.g., 20% of the initially selected labeled data)\n",
    "val_size = 0.2 # Adjust as needed, e.g., min 1 sample per class\n",
    "min_val_samples = config.num_classes\n",
    "actual_val_size = max(min_val_samples, int(len(train_val_df) * val_size)) \n",
    "\n",
    "if len(train_val_df) > actual_val_size:\n",
    "     labeled_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=actual_val_size, # Using test_size for validation set size\n",
    "        stratify=train_val_df['label'],\n",
    "        random_state=43 # Use a different random state\n",
    "    )\n",
    "else: # Handle cases where the initial labeled set is very small\n",
    "    labeled_df = train_val_df\n",
    "    # Sample a small validation set from the unlabeled data if needed\n",
    "    unlabeled_df, val_df = train_test_split(\n",
    "            unlabeled_df,\n",
    "            test_size=min(actual_val_size, len(unlabeled_df) // 2), # Take a small validation part\n",
    "            stratify=unlabeled_df['label'],\n",
    "            random_state=44\n",
    "    ) \n",
    "\n",
    "print(f\"Total training samples: {len(train_df_full)}\")\n",
    "print(f\"Labeled samples: {len(labeled_df)}\")\n",
    "print(f\"Unlabeled samples: {len(unlabeled_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Verify stratification (optional)\n",
    "print(\"\\nLabeled Set Class Distribution:\\n\", labeled_df['label'].value_counts())",
    "print(\"\\nValidation Set Class Distribution:\\n\", val_df['label'].value_counts())"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "model-md",
   "metadata": {},
   "source": [
    "### 5. Define the Model Architecture\n",
    "\n",
    "- Use a pre-trained ResNet18 as the backbone encoder.\n",
    "- Modify the first convolutional layer for 1-channel (spectrogram) input.\n",
    "- Remove the final fully connected layer.\n",
    "- Add a separate linear classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9670b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Define the Model Architecture\n",
    "# ----------------------------\n",
    "def create_model(num_classes, pretrained=True):\n",
    "    # Use a pretrained ResNet18 and modify first conv for 1-channel input.\n",
    "    base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
    "    # Modify the first convolutional layer to accept 1 input channel\n",
    "    base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    \n",
    "    # Feature encoder (remove the final fc layer)\n",
    "    encoder = nn.Sequential(*list(base_model.children())[:-1])\n",
    "    encoder_output_dim = base_model.fc.in_features # Get dim before final layer\n",
    "    \n",
    "    # Classifier head\n",
    "    classifier = nn.Linear(encoder_output_dim, num_classes)\n",
    "    \n",
    "    return encoder, classifier\n",
    "\n",
    "# Instantiate the TWO models (f and g) and their classifiers\n",
    "encoder_f, classifier_f = create_model(config.num_classes)\n",
    "encoder_g, classifier_g = create_model(config.num_classes)\n",
    "\n",
    "# Ensure models are separate instances (different initializations if pretrained=False, slightly different fine-tuning if True)\n",
    "encoder_g = copy.deepcopy(encoder_f) # Start with same weights if pretrained, but they'll diverge\n",
    "classifier_g = copy.deepcopy(classifier_f)\n",
    "\n",
    "model_f = nn.Sequential(encoder_f, nn.Flatten(), classifier_f).to(config.device)\n",
    "model_g = nn.Sequential(encoder_g, nn.Flatten(), classifier_g).to(config.device)\n",
    "\n",
    "# You can also define a forward function if you need more control\n",
    "# class JointMatchNet(nn.Module):\n",
    "#     def __init__(self, encoder, classifier):\n",
    "#         super().__init__()\n",
    "#         self.encoder = encoder\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.classifier = classifier\n",
    "#     def forward(self, x):\n",
    "#         features = self.encoder(x)\n",
    "#         flat_features = self.flatten(features)\n",
    "#         logits = self.classifier(flat_features)\n",
    "#         return logits\n",
    "# model_f = JointMatchNet(encoder_f, classifier_f).to(config.device)\n",
    "# model_g = JointMatchNet(encoder_g, classifier_g).to(config.device)\n",
    "\n",
    "print(\"Models created and moved to device.\")"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "loader-md",
   "metadata": {},
   "source": [
    "### 6. Create DataLoaders\n",
    "\n",
    "- Create separate DataLoaders for labeled, unlabeled, validation, and test sets.\n",
    "- Ensure the labeled and unlabeled loaders can be iterated together during training (e.g., using `itertools.cycle` if sizes differ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c27c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 6. Create DataLoaders\n",
    "# ----------------------------\n",
    "train_labeled_dataset = FreesoundLabeledDataset(labeled_df, config.audio_train_dir, label_map)\n",
    "train_unlabeled_dataset = FreesoundUnlabeledDataset(unlabeled_df, config.audio_train_dir, label_map)\n",
    "val_dataset = FreesoundTestDataset(val_df, config.audio_train_dir, label_map) # Use TestDataset structure for val\n",
    "test_dataset = FreesoundTestDataset(test_df, config.audio_test_dir, label_map)\n",
    "\n",
    "# Ensure labeled batch size isn't zero\n",
    "actual_labeled_bs = max(1, config.labeled_batch_size)\n",
    "actual_unlabeled_bs = config.batch_size - actual_labeled_bs \n",
    "if actual_unlabeled_bs <= 0:\n",
    "     print(\"Warning: Unlabeled batch size is zero or negative. Adjust batch_size or mu.\")\n",
    "     actual_unlabeled_bs = config.batch_size # Use full batch size if mu is 0\n",
    "\n",
    "print(f\"Actual Labeled BS for Loader: {actual_labeled_bs}\")\n",
    "print(f\"Actual Unlabeled BS for Loader: {actual_unlabeled_bs}\")\n",
    "\n",
    "labeled_loader = DataLoader(train_labeled_dataset, batch_size=actual_labeled_bs, shuffle=True, num_workers=2, drop_last=True)\n",
    "# drop_last=True is important for the unlabeled loader if its size isn't divisible by batch size\n",
    "unlabeled_loader = DataLoader(train_unlabeled_dataset, batch_size=actual_unlabeled_bs, shuffle=True, num_workers=2, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Loaders created. Num labeled batches: {len(labeled_loader)}, Num unlabeled batches: {len(unlabeled_loader)}\")"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "train-eval-md",
   "metadata": {},
   "source": [
    "### 7. Define Training and Evaluation Functions\n",
    "\n",
    "- **`train_one_epoch`**: Heavily modified for JointMatch.\n",
    "  - Takes both models, optimizers, labeled/unlabeled loaders, EMA probabilities (`pt`).\n",
    "  - Iterates through both loaders.\n",
    "  - Calculates supervised loss for both models on labeled data.\n",
    "  - Calculates unsupervised loss (cross-labeling, adaptive threshold, weighted disagreement) for both models on unlabeled data.\n",
    "  - Updates EMA probabilities.\n",
    "  - Backpropagates and updates both models.\n",
    "  - Returns average losses and accuracy on the labeled portion.\n",
    "- **`evaluate`**: Modified slightly.\n",
    "  - Takes one model (e.g., `model_f`) for evaluation.\n",
    "  - Calculates loss and accuracy on the provided dataloader (validation or test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518d32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 7. Training and Evaluation Functions\n",
    "# ---------------------------------------\n",
    "\n",
    "def train_one_epoch(model_f, model_g, optimizer_f, optimizer_g, labeled_loader, unlabeled_loader, criterion_s, criterion_u, pt, epoch):\n",
    "    model_f.train()\n",
    "    model_g.train()\n",
    "    \n",
    "    running_loss_s_f = 0.0\n",
    "    running_loss_u_f = 0.0\n",
    "    running_loss_s_g = 0.0\n",
    "    running_loss_u_g = 0.0\n",
    "    correct_f = 0\n",
    "    correct_g = 0\n",
    "    total_labeled = 0\n",
    "    mask_ratios = []\n",
    "\n",
    "    # Use tqdm for progress bar, iterate up to the length of the longest loader \n",
    "    # Typically unlabeled loader is much larger, use it to define epoch length\n",
    "    num_batches = len(unlabeled_loader)\n",
    "    train_iterator = tqdm(zip(itertools.cycle(labeled_loader), unlabeled_loader), total=num_batches, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for (inputs_l, labels_l), (inputs_u_w, inputs_u_s) in train_iterator:\n",
    "        inputs_l, labels_l = inputs_l.to(config.device), labels_l.to(config.device)\n",
    "        inputs_u_w, inputs_u_s = inputs_u_w.to(config.device), inputs_u_s.to(config.device)\n",
    "        \n",
    "        labeled_bs = inputs_l.size(0)\n",
    "        unlabeled_bs = inputs_u_w.size(0)\n",
    "        batch_size = labeled_bs + unlabeled_bs # Should match config.batch_size ideally\n",
    "        \n",
    "        # --- Supervised Loss --- \n",
    "        logits_f_l = model_f(inputs_l)\n",
    "        logits_g_l = model_g(inputs_l)\n",
    "        \n",
    "        loss_s_f = criterion_s(logits_f_l, labels_l)\n",
    "        loss_s_g = criterion_s(logits_g_l, labels_l)\n",
    "        \n",
    "        # --- Unsupervised Loss --- \n",
    "        with torch.no_grad():\n",
    "            # Get predictions on weakly augmented data\n",
    "            logits_f_u_w = model_f(inputs_u_w)\n",
    "            logits_g_u_w = model_g(inputs_u_w)\n",
    "            probs_f_u_w = torch.softmax(logits_f_u_w, dim=1)\n",
    "            probs_g_u_w = torch.softmax(logits_g_u_w, dim=1)\n",
    "            \n",
    "            # Update EMA probabilities (pt)\n",
    "            # Average probabilities from both models for pt update might be more stable\n",
    "            avg_probs_u_w = (probs_f_u_w + probs_g_u_w) / 2\n",
    "            # Detach is important here if pt is used elsewhere with gradients\n",
    "            pt.data = config.ema_decay * pt.data + (1 - config.ema_decay) * avg_probs_u_w.mean(0).detach()\n",
    "            \n",
    "            # Calculate adaptive thresholds T(c)\n",
    "            pt_normalized = pt / pt.max() # Normalize pt\n",
    "            thresholds = pt_normalized * config.threshold # Shape: [num_classes]\n",
    "            thresholds = thresholds.to(config.device)\n",
    "\n",
    "            # Generate pseudo-labels using cross-labeling and adaptive thresholds\n",
    "            max_probs_f, pseudo_labels_f = torch.max(probs_f_u_w, dim=1)\n",
    "            max_probs_g, pseudo_labels_g = torch.max(probs_g_u_w, dim=1)\n",
    "            \n",
    "            # Create masks based on class-specific thresholds\n",
    "            mask_f = max_probs_f >= thresholds[pseudo_labels_f]\n",
    "            mask_g = max_probs_g >= thresholds[pseudo_labels_g]\n",
    "            mask_f = mask_f.float()\n",
    "            mask_g = mask_g.float()\n",
    "            mask_ratios.append((mask_f.mean().item() + mask_g.mean().item()) / 2)\n",
    "            \n",
    "            # Calculate disagreement weight wb (higher weight for disagreement)\n",
    "            disagreement_mask = (pseudo_labels_f != pseudo_labels_g)\n",
    "            # Weight = delta if disagree, (1-delta) if agree\n",
    "            wb = torch.where(disagreement_mask, config.delta, 1.0 - config.delta) \n",
    "            wb = wb.float().to(config.device)\n",
    "\n",
    "        # Get predictions on strongly augmented data\n",
    "        logits_f_u_s = model_f(inputs_u_s)\n",
    "        logits_g_u_s = model_g(inputs_u_s)\n",
    "\n",
    "        # Calculate unsupervised loss (cross-entropy with pseudo-labels from the *other* model)\n",
    "        # Use reduction='none' to apply mask and weight\n",
    "        loss_u_f_vec = criterion_u(logits_f_u_s, pseudo_labels_g) \n",
    "        loss_u_f = (loss_u_f_vec * mask_g * wb).mean()\n",
    "        \n",
    "        loss_u_g_vec = criterion_u(logits_g_u_s, pseudo_labels_f)\n",
    "        loss_u_g = (loss_u_g_vec * mask_f * wb).mean()\n",
    "\n",
    "        # --- Combine Losses --- \n",
    "        total_loss_f = loss_s_f + config.wu * loss_u_f\n",
    "        total_loss_g = loss_s_g + config.wu * loss_u_g\n",
    "\n",
    "        # --- Backpropagation and Optimization --- \n",
    "        optimizer_f.zero_grad()\n",
    "        total_loss_f.backward()\n",
    "        optimizer_f.step()\n",
    "        \n",
    "        optimizer_g.zero_grad()\n",
    "        total_loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # --- Statistics --- \n",
    "        running_loss_s_f += loss_s_f.item() * labeled_bs\n",
    "        running_loss_u_f += loss_u_f.item() * unlabeled_bs\n",
    "        running_loss_s_g += loss_s_g.item() * labeled_bs\n",
    "        running_loss_u_g += loss_u_g.item() * unlabeled_bs\n",
    "        \n",
    "        preds_f = logits_f_l.argmax(dim=1)\n",
    "        preds_g = logits_g_l.argmax(dim=1)\n",
    "        correct_f += (preds_f == labels_l).sum().item()\n",
    "        correct_g += (preds_g == labels_l).sum().item()\n",
    "        total_labeled += labeled_bs\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_iterator.set_postfix(loss_f=f\"{total_loss_f.item():.4f}\", loss_g=f\"{total_loss_g.item():.4f}\", mask=f\"{np.mean(mask_ratios[-10:]):.2f}\") # Show rolling avg mask\n",
    "            \n",
    "    avg_loss_s_f = running_loss_s_f / total_labeled if total_labeled > 0 else 0\n",
    "    avg_loss_u_f = running_loss_u_f / (num_batches * config.unlabeled_batch_size) if num_batches > 0 else 0\n",
    "    avg_loss_s_g = running_loss_s_g / total_labeled if total_labeled > 0 else 0\n",
    "    avg_loss_u_g = running_loss_u_g / (num_batches * config.unlabeled_batch_size) if num_batches > 0 else 0\n",
    "    \n",
    "    acc_f = correct_f / total_labeled if total_labeled > 0 else 0\n",
    "    acc_g = correct_g / total_labeled if total_labeled > 0 else 0\n",
    "    avg_mask_ratio = np.mean(mask_ratios) if mask_ratios else 0\n",
    "    \n",
    "    # Average metrics for reporting (can report separately too)\n",
    "    avg_acc = (acc_f + acc_g) / 2\n",
    "    avg_loss_s = (avg_loss_s_f + avg_loss_s_g) / 2\n",
    "    avg_loss_u = (avg_loss_u_f + avg_loss_u_g) / 2\n",
    "\n",
    "    return avg_loss_s, avg_loss_u, avg_acc, avg_mask_ratio, pt # Return updated pt\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    epoch_loss = running_loss / total if total > 0 else 0\n",
    "    epoch_acc = correct / total if total > 0 else 0\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "train-loop-md",
   "metadata": {},
   "source": [
    "### 8. Training Loop\n",
    "\n",
    "- Initialize models, optimizers, loss functions, and EMA probabilities (`pt`).\n",
    "- Loop through epochs, calling `train_one_epoch` and `evaluate`.\n",
    "- Keep track of the best validation accuracy and save the corresponding model states (for both models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6a48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 8. Training Loop \n",
    "# ----------------------------\n",
    "criterion_s = nn.CrossEntropyLoss() # Supervised loss\n",
    "criterion_u = nn.CrossEntropyLoss(reduction='none') # Unsupervised loss (no reduction initially)\n",
    "\n",
    "# Separate optimizers for each model\n",
    "optimizer_f = optim.Adam(model_f.parameters(), lr=config.lr)\n",
    "optimizer_g = optim.Adam(model_g.parameters(), lr=config.lr)\n",
    "\n",
    "# Initialize EMA probabilities (pt) - uniform initially\n",
    "pt = torch.ones(config.num_classes) / config.num_classes \n",
    "pt = pt.to(config.device)\n",
    "\n",
    "train_losses_s, train_losses_u, train_accs = [], [], []\n",
    "val_losses, val_accs = [], []\n",
    "mask_ratios_log = []\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    tr_loss_s, tr_loss_u, tr_acc, mask_ratio, pt = train_one_epoch(\n",
    "        model_f, model_g, optimizer_f, optimizer_g, \n",
    "        labeled_loader, unlabeled_loader, \n",
    "        criterion_s, criterion_u, pt, epoch\n",
    "    )\n",
    "    # Evaluate using one model (e.g., model_f, or average predictions if desired)\n",
    "    val_loss, val_acc, _, _ = evaluate(model_f, val_loader, criterion_s, config.device) \n",
    "    \n",
    "    train_losses_s.append(tr_loss_s)\n",
    "    train_losses_u.append(tr_loss_u)\n",
    "    train_accs.append(tr_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    mask_ratios_log.append(mask_ratio)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config.epochs} -> \"\n",
    "          f\"Train Loss S: {tr_loss_s:.4f}, Train Loss U: {tr_loss_u:.4f}, Train Acc (L): {tr_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | Mask Ratio: {mask_ratio:.3f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        print(f\"*** New best validation accuracy: {best_val_acc:.4f}. Saving models... ***\")\n",
    "        torch.save(model_f.state_dict(), config.model_save_path_f)\n",
    "        torch.save(model_g.state_dict(), config.model_save_path_g)\n",
    "\n",
    "# Load best model for final evaluation (using model_f as the evaluation model)\n",
    "print(f\"\\nLoading best model (model_f) from {config.model_save_path_f} with Val Acc: {best_val_acc:.4f}\")\n",
    "try:\n",
    "    # Recreate model structure before loading state_dict\n",
    "    encoder_f_best, classifier_f_best = create_model(config.num_classes, pretrained=False) # Don't need pretrained weights now\n",
    "    model_f_best = nn.Sequential(encoder_f_best, nn.Flatten(), classifier_f_best).to(config.device)\n",
    "    model_f_best.load_state_dict(torch.load(config.model_save_path_f, map_location=config.device))\n",
    "    print(\"Best model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading best model: {e}. Using the last epoch model for evaluation.\")\n",
    "    model_f_best = model_f # Fallback to the model from the last epoch\n"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "eval-metrics-md",
   "metadata": {},
   "source": [
    "### 9. Evaluate on Test Set and Compute Metrics\n",
    "\n",
    "- Load the best-performing model (saved based on validation accuracy).\n",
    "- Run the `evaluate` function on the `test_loader`.\n",
    "- Print the final test accuracy, classification report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36320496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# 9. Evaluate on Test and Compute Metrics\n",
    "# ------------------------------------------\n",
    "test_loss, test_acc, y_pred, y_true = evaluate(model_f_best, test_loader, criterion_s, config.device)\n",
    "print(f\"\\nFinal Test Results using Best Model (model_f):\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix on Test Set:\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix on Test Data (JointMatch)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "curves-md",
   "metadata": {},
   "source": [
    "### 10. Plot Training Curves\n",
    "\n",
    "- Plot the supervised training loss, unsupervised training loss, training accuracy (on labeled data), and validation accuracy/loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e7695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 10. Plot Training Curves\n",
    "# ----------------------------\n",
    "epochs_range = range(1, config.epochs + 1)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_range, train_losses_s, label='Train Loss (Supervised)')\n",
    "plt.plot(epochs_range, train_losses_u, label='Train Loss (Unsupervised)')\n",
    "plt.plot(epochs_range, val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, train_accs, label='Train Acc (on Labeled)')\n",
    "plt.plot(epochs_range, val_accs, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs_range, mask_ratios_log, label='Pseudo-Label Mask Ratio')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Mask Ratio Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle('JointMatch Training Progress')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 862232,
     "sourceId": 8900,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
