{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPASS for Semi-Supervised Learning (Text Classification)\n",
    "\n",
    "This notebook implements the EPASS approach for Semi-Supervised Learning on a text classification task, adapting concepts from the paper (originally for images) to text data. It incorporates:\n",
    "- BERT as the base encoder.\n",
    "- Ensemble Projectors for generating embeddings.\n",
    "- An Exponential Moving Average (EMA) teacher model.\n",
    "- A Memory Bank for contrastive learning.\n",
    "- SSL loss components: Supervised (Ls), Unsupervised Consistency (Lu), and Contrastive (Lc).\n",
    "- Techniques to mitigate CUDA OOM errors: Automatic Mixed Precision (AMP) and Gradient Accumulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm # For progress bars\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "# Set environment variable for synchronous CUDA execution (debugging)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
    "BERT_OUTPUT_DIM = 768\n",
    "PROJECTOR_DIM = 128 # As mentioned in paper\n",
    "EMBEDDING_DIM = 128 # Output dim of projector MLP's final layer\n",
    "NUM_PROJECTORS = 3 # As used in paper's ablation\n",
    "NUM_CLASSES = -1 # Initialize as -1, will be set during data loading\n",
    "\n",
    "# SSL Params (Example values, tune as needed)\n",
    "LABELED_RATIO = 0.1 # Use 10% of training data as labeled\n",
    "CONFIDENCE_THRESHOLD = 0.95 # Tau (Ï„) for pseudo-labeling\n",
    "TEMPERATURE = 0.1 # T for contrastive loss\n",
    "MOMENTUM = 0.999 # m for EMA teacher update\n",
    "LAMBDA_U = 1.0 # Weight for unsupervised classification loss (Lu)\n",
    "LAMBDA_C = 1.0 # Weight for contrastive loss (Lc)\n",
    "MEM_BANK_SIZE = 4096 # K, size of the memory bank (adjust based on resources/dataset)\n",
    "\n",
    "# Training Params\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 4 # <<< REDUCED for OOM issues\n",
    "UNLABELED_BATCH_SIZE_MULTIPLIER = 2 # mu << Use a fixed multiplier\n",
    "LR = 1e-5 # Learning rate for BERT fine-tuning (often lower)\n",
    "EPOCHS = 3 # Adjust as needed\n",
    "GRADIENT_ACCUMULATION_STEPS = 4 # <<< ADDED for OOM issues\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Tokenizer and Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "print(\"Loading base BERT model...\")\n",
    "# We load the base model later inside the main execution block to ensure fresh instances\n",
    "# bert_model = BertModel.from_pretrained(PRETRAINED_MODEL)\n",
    "print(\"Tokenizer loaded. Base models will be loaded later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading Function (Corrected for Header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_csv(train_path, test_path):\n",
    "    \"\"\"Loads train/test CSVs, explicitly using the first row as the header.\"\"\"\n",
    "    global NUM_CLASSES # Ensure we modify the global variable\n",
    "    print(f\"Attempting to load train data from: {train_path} (assuming header in row 0)\")\n",
    "    try:\n",
    "        # Explicitly use the first row as header\n",
    "        train_df = pd.read_csv(train_path, header=0, low_memory=False)\n",
    "        print(\"Train data columns loaded:\", train_df.columns.tolist())\n",
    "\n",
    "        # Check for required columns\n",
    "        if 'label' not in train_df.columns or ('content' not in train_df.columns and 'title' not in train_df.columns):\n",
    "             raise ValueError(\"Train CSV must contain 'label' and ('content' or 'title') columns in the header.\")\n",
    "\n",
    "        # Robustly convert 'label' to numeric, drop rows that fail (like the header itself)\n",
    "        train_df['label'] = pd.to_numeric(train_df['label'], errors='coerce') # Coerce errors to NaN\n",
    "        initial_train_count = len(train_df)\n",
    "        train_df.dropna(subset=['label'], inplace=True) # Drop rows where label conversion failed\n",
    "        print(f\"Dropped {initial_train_count - len(train_df)} train rows due to non-numeric labels.\")\n",
    "        if len(train_df) == 0: raise ValueError(\"No valid numeric labels found in train data after cleaning.\")\n",
    "        train_df['label'] = train_df['label'].astype(int) - 1 # Convert to 0-based index\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing train data: {e}\")\n",
    "        raise # Re-raise the exception after printing\n",
    "\n",
    "    print(f\"Attempting to load test data from: {test_path} (assuming header in row 0)\")\n",
    "    try:\n",
    "        test_df = pd.read_csv(test_path, header=0, low_memory=False)\n",
    "        print(\"Test data columns loaded:\", test_df.columns.tolist())\n",
    "\n",
    "        if 'label' not in test_df.columns or ('content' not in test_df.columns and 'title' not in test_df.columns):\n",
    "             raise ValueError(\"Test CSV must contain 'label' and ('content' or 'title') columns in the header.\")\n",
    "\n",
    "        test_df['label'] = pd.to_numeric(test_df['label'], errors='coerce')\n",
    "        initial_test_count = len(test_df)\n",
    "        test_df.dropna(subset=['label'], inplace=True)\n",
    "        print(f\"Dropped {initial_test_count - len(test_df)} test rows due to non-numeric labels.\")\n",
    "        if len(test_df) == 0: raise ValueError(\"No valid numeric labels found in test data after cleaning.\")\n",
    "        test_df['label'] = test_df['label'].astype(int) - 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing test data: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Ensure 'content' column exists, fallback to 'title' if necessary\n",
    "    if 'content' not in train_df.columns and 'title' in train_df.columns:\n",
    "        print(\"Warning: 'content' column missing in train_df, using 'title' instead.\")\n",
    "        train_df['content'] = train_df['title']\n",
    "    if 'content' not in test_df.columns and 'title' in test_df.columns:\n",
    "        print(\"Warning: 'content' column missing in test_df, using 'title' instead.\")\n",
    "        test_df['content'] = test_df['title']\n",
    "\n",
    "    # Final check for required columns after potential fallback\n",
    "    if 'content' not in train_df.columns or 'label' not in train_df.columns:\n",
    "        raise ValueError(\"Train DataFrame must contain 'label' and 'content' (derived from 'title' if needed) columns.\")\n",
    "    if 'content' not in test_df.columns or 'label' not in test_df.columns:\n",
    "         raise ValueError(\"Test DataFrame must contain 'label' and 'content' (derived from 'title' if needed) columns.\")\n",
    "\n",
    "\n",
    "    # --- Crucial: Verify and Set NUM_CLASSES --- \n",
    "    train_min_label = train_df['label'].min()\n",
    "    train_max_label = train_df['label'].max()\n",
    "    test_min_label = test_df['label'].min()\n",
    "    test_max_label = test_df['label'].max()\n",
    "\n",
    "    print(f\"Train labels after processing: Min={train_min_label}, Max={train_max_label}\")\n",
    "    print(f\"Test labels after processing: Min={test_min_label}, Max={test_max_label}\")\n",
    "\n",
    "    if train_min_label < 0 or test_min_label < 0:\n",
    "         print(\"Warning: Negative labels detected after processing. Check label conversion logic.\")\n",
    "         # Optionally raise an error here if negative labels are strictly invalid\n",
    "         # raise ValueError(\"Negative labels found after processing.\")\n",
    "         \n",
    "    # Set NUM_CLASSES based on the highest label index + 1 found in EITHER train or test\n",
    "    # This handles cases where test set might have labels not seen in the small labeled training split\n",
    "    determined_num_classes = max(train_max_label, test_max_label) + 1\n",
    "    if determined_num_classes <= 0:\n",
    "         raise ValueError(\"Could not determine a valid number of classes (max label < 0).\")\n",
    "         \n",
    "    NUM_CLASSES = determined_num_classes\n",
    "    print(f\"Data loaded successfully. Num classes set to: {NUM_CLASSES} (based on max label {NUM_CLASSES - 1})\")\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSLTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, is_labeled=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels # Will be -1 or similar for unlabeled\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_labeled = is_labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Handle potential NaN or non-string data robustly\n",
    "        text = str(self.texts[index]) if pd.notna(self.texts[index]) else \"\"\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding=\"max_length\",\n",
    "                                   max_length=self.max_len, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            'text': text, \n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'is_labeled': torch.tensor(self.is_labeled, dtype=torch.bool)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. EPASS Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPASSModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, bert_output_dim, projector_dim, embedding_dim, num_projectors):\n",
    "        super(EPASSModel, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.num_projectors = num_projectors\n",
    "\n",
    "        if num_classes <= 0:\n",
    "            raise ValueError(f\"EPASSModel received invalid num_classes: {num_classes}\")\n",
    "\n",
    "        self.projectors = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(bert_output_dim, projector_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(projector_dim, embedding_dim)\n",
    "            ) for _ in range(num_projectors)\n",
    "        ])\n",
    "        self.classifier = nn.Linear(bert_output_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, return_features=False):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        features = outputs.last_hidden_state[:, 0, :] \n",
    "        embeddings = [proj(features) for proj in self.projectors]\n",
    "        stacked_embeddings = torch.stack(embeddings, dim=0)\n",
    "        ensemble_embedding = torch.mean(stacked_embeddings, dim=0)\n",
    "        normalized_embedding = F.normalize(ensemble_embedding, p=2, dim=1)\n",
    "        logits = self.classifier(features)\n",
    "\n",
    "        if return_features:\n",
    "            return logits, normalized_embedding, features \n",
    "        else:\n",
    "            return logits, normalized_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. EMA Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Memory Bank Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBank:\n",
    "    def __init__(self, size, embedding_dim, num_classes, device):\n",
    "        self.size = size\n",
    "        self.device = device\n",
    "        if num_classes <= 0:\n",
    "            raise ValueError(f\"MemoryBank received invalid num_classes: {num_classes}\")\n",
    "        self.embeddings = torch.randn(size, embedding_dim).to(device)\n",
    "        self.embeddings = F.normalize(self.embeddings, dim=1)\n",
    "        self.labels = torch.randint(0, num_classes, (size,)).to(device) \n",
    "        self.ptr = 0\n",
    "        print(f\"Memory Bank initialized with size {size}, embedding_dim {embedding_dim}, num_classes {num_classes}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, embeddings, labels):\n",
    "        batch_size = embeddings.size(0)\n",
    "        if batch_size == 0: return \n",
    "        embeddings = F.normalize(embeddings, dim=1)\n",
    "        indices = torch.arange(self.ptr, self.ptr + batch_size).fmod(self.size).long()\n",
    "        indices = indices[indices < self.size]\n",
    "        valid_batch_size = len(indices)\n",
    "        if valid_batch_size < batch_size:\n",
    "           # print(f\"Warning: Updating memory bank with only {valid_batch_size}/{batch_size} elements due to index wrapping.\")\n",
    "           embeddings = embeddings[:valid_batch_size]\n",
    "           labels = labels[:valid_batch_size]\n",
    "        if valid_batch_size > 0:\n",
    "           self.embeddings.index_copy_(0, indices, embeddings.detach())\n",
    "           self.labels.index_copy_(0, indices, labels.detach())\n",
    "           self.ptr = (self.ptr + valid_batch_size) % self.size\n",
    "\n",
    "    def get_all(self):\n",
    "        return self.embeddings, self.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Loss Calculation Function (with Checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss_fn = nn.CrossEntropyLoss()\n",
    "ce_loss_fn_reduction_none = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "def calculate_losses(student_model, ema_model, memory_bank, labeled_batch, unlabeled_batch, criterion_ce, criterion_ce_noreduction, temp, threshold, lambda_u, lambda_c, device):\n",
    "    \"\"\"Calculates Ls, Lu, Lc and the combined loss with label range checks.\"\"\"\n",
    "    Ls = torch.tensor(0.0, device=device, requires_grad=True) # Ensure Ls requires grad if it's the only term\n",
    "    Lu = torch.tensor(0.0).to(device)\n",
    "    Lc = torch.tensor(0.0).to(device)\n",
    "\n",
    "    # 1. Supervised Loss (Ls)\n",
    "    if labeled_batch is not None and len(labeled_batch['input_ids']) > 0:\n",
    "        l_input_ids = labeled_batch['input_ids'].to(device)\n",
    "        l_attn_mask = labeled_batch['attention_mask'].to(device)\n",
    "        l_labels = labeled_batch['label'].to(device)\n",
    "\n",
    "        # Check labeled data labels\n",
    "        if l_labels.min() < 0 or l_labels.max() >= NUM_CLASSES:\n",
    "             print(f\"!!! Invalid label detected in labeled batch: min={l_labels.min()}, max={l_labels.max()}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "             # Ls remains 0.0 with requires_grad=True\n",
    "        else:\n",
    "            student_logits_l, _ = student_model(l_input_ids, l_attn_mask)\n",
    "            Ls = criterion_ce(student_logits_l, l_labels)\n",
    "            if torch.isnan(Ls) or torch.isinf(Ls):\n",
    "                 print(\"NaN/Inf Ls detected!\")\n",
    "                 Ls = torch.tensor(0.0, device=device, requires_grad=True) # Reset if bad\n",
    "\n",
    "    # 2. Unsupervised Losses (Lu and Lc)\n",
    "    if unlabeled_batch is not None and len(unlabeled_batch['input_ids']) > 0:\n",
    "        u_input_ids = unlabeled_batch['input_ids'].to(device)\n",
    "        u_attn_mask = unlabeled_batch['attention_mask'].to(device)\n",
    "        batch_size_u = u_input_ids.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ema_logits_weak, ema_embed_weak = ema_model(u_input_ids, u_attn_mask)\n",
    "            ema_probs_weak = torch.softmax(ema_logits_weak, dim=1)\n",
    "            pseudo_labels = torch.argmax(ema_probs_weak, dim=1)\n",
    "            max_probs = torch.max(ema_probs_weak, dim=1)[0]\n",
    "            mask = max_probs.ge(threshold).float()\n",
    "\n",
    "            # Check pseudo-labels\n",
    "            if (pseudo_labels.min() < 0 or pseudo_labels.max() >= NUM_CLASSES):\n",
    "                 print(f\"!!! Invalid pseudo_label detected OUTSIDE forward pass: min={pseudo_labels.min()}, max={pseudo_labels.max()}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "                 # We might invalidate the mask for these specific indices later if needed\n",
    "                 # Or rely on the check within Lu/Lc calculation\n",
    "\n",
    "        student_logits_strong, student_embed_strong = student_model(u_input_ids, u_attn_mask)\n",
    "\n",
    "        # 2a. Lu\n",
    "        if mask.sum() > 0:\n",
    "            confident_indices_bool = mask.bool()\n",
    "            valid_pseudo_labels = pseudo_labels[confident_indices_bool]\n",
    "            if valid_pseudo_labels.min() < 0 or valid_pseudo_labels.max() >= NUM_CLASSES:\n",
    "                 print(f\"!!! Invalid pseudo_label detected *among confident samples* for Lu: min={valid_pseudo_labels.min()}, max={valid_pseudo_labels.max()}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "                 # Set Lu to 0 for this batch to avoid crash\n",
    "                 Lu = torch.tensor(0.0).to(device)\n",
    "            else:\n",
    "                # Apply loss only to confident samples using the mask\n",
    "                loss_u_per_sample = criterion_ce_noreduction(student_logits_strong, pseudo_labels)\n",
    "                Lu = (loss_u_per_sample * mask).mean()\n",
    "                if torch.isnan(Lu) or torch.isinf(Lu):\n",
    "                     print(\"NaN/Inf Lu detected!\")\n",
    "                     Lu = torch.tensor(0.0).to(device)\n",
    "\n",
    "\n",
    "        # 2b. Lc\n",
    "        mem_embeddings, mem_labels = memory_bank.get_all()\n",
    "        if mem_embeddings is not None and mem_embeddings.size(0) > 0 and mask.sum() > 0:\n",
    "            confident_indices_bool = mask.bool()\n",
    "            valid_pseudo_labels_for_lc = pseudo_labels[confident_indices_bool]\n",
    "            valid_student_embed_strong = student_embed_strong[confident_indices_bool]\n",
    "            current_batch_size_u_confident = valid_student_embed_strong.size(0)\n",
    "\n",
    "            if valid_pseudo_labels_for_lc.min() < 0 or valid_pseudo_labels_for_lc.max() >= NUM_CLASSES:\n",
    "                print(f\"!!! Invalid pseudo_label detected *among confident samples* for Lc: min={valid_pseudo_labels_for_lc.min()}, max={valid_pseudo_labels_for_lc.max()}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "                Lc = torch.tensor(0.0).to(device) \n",
    "            elif mem_labels.min() < 0 or mem_labels.max() >= NUM_CLASSES:\n",
    "                 print(f\"!!! Invalid label detected in memory bank for Lc: min={mem_labels.min()}, max={mem_labels.max()}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "                 Lc = torch.tensor(0.0).to(device)\n",
    "            else:\n",
    "                # Calculate Lc only for confident samples\n",
    "                sim_matrix = torch.mm(valid_student_embed_strong, mem_embeddings.t()) / temp \n",
    "                labels_matrix = valid_pseudo_labels_for_lc.unsqueeze(1).expand(-1, memory_bank.size)\n",
    "                mem_labels_matrix = mem_labels.unsqueeze(0).expand(current_batch_size_u_confident, -1)\n",
    "                positive_mask = (labels_matrix == mem_labels_matrix).float().to(device)\n",
    "                \n",
    "                log_probs_contrastive = F.log_softmax(sim_matrix, dim=1)\n",
    "                num_positives = positive_mask.sum(dim=1, keepdim=True)\n",
    "                target_dist = positive_mask / (num_positives + 1e-9)\n",
    "                \n",
    "                Lc_per_sample = -(target_dist * log_probs_contrastive).sum(dim=1)\n",
    "                Lc = Lc_per_sample.mean() # Average over the confident samples\n",
    "                if torch.isnan(Lc) or torch.isinf(Lc):\n",
    "                     print(\"NaN/Inf Lc detected!\")\n",
    "                     Lc = torch.tensor(0.0).to(device)\n",
    "\n",
    "        # Update memory bank \n",
    "        confident_indices = mask.bool()\n",
    "        if confident_indices.sum() > 0:\n",
    "           labels_to_update = pseudo_labels[confident_indices]\n",
    "           if labels_to_update.min() >= 0 and labels_to_update.max() < NUM_CLASSES:\n",
    "                memory_bank.update(ema_embed_weak[confident_indices], labels_to_update)\n",
    "           else:\n",
    "                print(f\"!!! Skipping memory bank update due to invalid pseudo-labels: min={labels_to_update.min()}, max={labels_to_update.max()}\")\n",
    "\n",
    "    # Ensure loss requires grad if Ls was skipped but Lu/Lc were calculated\n",
    "    if not labeled_batch and (unlabeled_batch is not None and len(unlabeled_batch['input_ids']) > 0):\n",
    "        loss = lambda_u * Lu + lambda_c * Lc\n",
    "        # Manually set requires_grad if needed (though backward should handle it)\n",
    "        if loss.requires_grad is False and (student_model.training): # Check if student model has grads enabled\n",
    "             # Find a parameter in the student model that requires grad\n",
    "             grad_param = next((p for p in student_model.parameters() if p.requires_grad), None)\n",
    "             if grad_param is not None:\n",
    "                 loss = loss + 0.0 * grad_param.sum() # Add zero contribution from a grad-requiring param\n",
    "             else:\n",
    "                 print(\"Warning: Could not make unsupervised loss require gradients.\")\n",
    "    elif labeled_batch is not None and len(labeled_batch['input_ids']) > 0:\n",
    "        loss = Ls + lambda_u * Lu + lambda_c * Lc\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=device, requires_grad=True) # Default requires grad if no data\n",
    "        \n",
    "    # Final check for safety\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(\"NaN/Inf combined loss detected!\")\n",
    "        return torch.tensor(0.0, device=device, requires_grad=True), Ls, Lu, Lc # Return zero loss requiring grad\n",
    "\n",
    "    return loss, Ls, Lu, Lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Loop Function (AMP + Accumulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ssl_model(student_model, ema_model, memory_bank, labeled_loader, unlabeled_loader, optimizer, criterion_ce, criterion_ce_noreduction, device, epochs, momentum, temp, threshold, lambda_u, lambda_c, accumulation_steps=1):\n",
    "\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    student_model.to(device)\n",
    "    ema_model.to(device)\n",
    "    ema_model.eval()\n",
    "\n",
    "    # Handle potential None loaders or empty datasets\n",
    "    unlabeled_iter = iter(unlabeled_loader) if unlabeled_loader and len(unlabeled_loader.dataset) > 0 else None\n",
    "    num_labeled_batches = len(labeled_loader) if labeled_loader and len(labeled_loader.dataset) > 0 else 0\n",
    "\n",
    "    global_step = 0\n",
    "    print(f\"Starting training with AMP={'Enabled' if use_amp else 'Disabled'} and gradient accumulation (steps={accumulation_steps})...\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_Ls, total_Lu, total_Lc = 0, 0, 0, 0\n",
    "        num_optimizer_steps_in_epoch = 0\n",
    "        num_batches_processed = 0\n",
    "\n",
    "        if num_labeled_batches == 0 and unlabeled_loader is None:\n",
    "             print(f\"Epoch {epoch+1}: No data to process. Skipping.\")\n",
    "             continue\n",
    "\n",
    "        optimizer.zero_grad() # Zero gradients at the start of epoch accumulation cycle\n",
    "\n",
    "        # Determine the iterator to drive the epoch\n",
    "        if num_labeled_batches > 0:\n",
    "            loop_iterator = labeled_loader\n",
    "            loop_length = num_labeled_batches\n",
    "        elif unlabeled_loader:\n",
    "            loop_iterator = range(len(unlabeled_loader)) # Use range if only unlabeled\n",
    "            loop_length = len(unlabeled_loader)\n",
    "        else:\n",
    "            loop_iterator = range(0) # Empty loop\n",
    "            loop_length = 0\n",
    "            \n",
    "        progress_bar = tqdm(loop_iterator, desc=f\"Epoch {epoch+1}/{epochs}\", total=loop_length)\n",
    "\n",
    "        for i, data_batch in enumerate(progress_bar):\n",
    "            student_model.train()\n",
    "\n",
    "            # Assign labeled/unlabeled based on loop driver\n",
    "            current_labeled_batch = data_batch if num_labeled_batches > 0 else None\n",
    "            current_unlabeled_batch = None\n",
    "            if unlabeled_iter:\n",
    "                try:\n",
    "                    current_unlabeled_batch = next(unlabeled_iter)\n",
    "                except StopIteration:\n",
    "                    if unlabeled_loader is None: continue\n",
    "                    unlabeled_iter = iter(unlabeled_loader)\n",
    "                    current_unlabeled_batch = next(unlabeled_iter)\n",
    "            \n",
    "            # If loop is driven by unlabeled data, labeled batch is None\n",
    "            if num_labeled_batches == 0:\n",
    "                 current_labeled_batch = None\n",
    "                 # We need to fetch the unlabeled batch if the loop is driven by range\n",
    "                 if not isinstance(data_batch, dict) and current_unlabeled_batch is None: # Check if data_batch is just an index\n",
    "                      if unlabeled_iter: # Try fetching again if somehow missed\n",
    "                           try:\n",
    "                               current_unlabeled_batch = next(unlabeled_iter)\n",
    "                           except StopIteration:\n",
    "                               print(\"Warning: Unlabeled iterator ended unexpectedly.\")\n",
    "                               continue\n",
    "                      else:\n",
    "                           print(\"Warning: No unlabeled iterator available.\")\n",
    "                           continue\n",
    "\n",
    "            if current_labeled_batch is None and current_unlabeled_batch is None:\n",
    "                print(\"Warning: Both labeled and unlabeled batches are None in loop. Skipping step.\")\n",
    "                continue\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                loss, Ls, Lu, Lc = calculate_losses(\n",
    "                    student_model, ema_model, memory_bank,\n",
    "                    current_labeled_batch, current_unlabeled_batch,\n",
    "                    ce_loss_fn, ce_loss_fn_reduction_none,\n",
    "                    TEMPERATURE, CONFIDENCE_THRESHOLD, LAMBDA_U, LAMBDA_C, DEVICE\n",
    "                )\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"NaN/Inf loss detected at step {global_step}, epoch {epoch+1}, batch {i}. Skipping update.\")\n",
    "                    if (i + 1) % accumulation_steps == 0 or (i + 1) == loop_length:\n",
    "                         optimizer.zero_grad()\n",
    "                    continue\n",
    "\n",
    "                loss = loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            num_batches_processed += 1\n",
    "            total_loss += loss.item() * accumulation_steps\n",
    "            total_Ls += Ls.item() if current_labeled_batch is not None else 0\n",
    "            total_Lu += Lu.item() if current_unlabeled_batch is not None else 0\n",
    "            total_Lc += Lc.item() if current_unlabeled_batch is not None else 0\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0 or (i + 1) == loop_length:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                update_ema_variables(student_model, ema_model, MOMENTUM, global_step)\n",
    "                num_optimizer_steps_in_epoch += 1\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            if isinstance(progress_bar, tqdm):\n",
    "                 progress_bar.set_postfix({\n",
    "                     'Loss': f\"{loss.item() * accumulation_steps:.4f}\",\n",
    "                     'Ls': f\"{Ls.item():.4f}\",\n",
    "                     'Lu': f\"{Lu.item():.4f}\",\n",
    "                     'Lc': f\"{Lc.item():.4f}\"\n",
    "                 })\n",
    "\n",
    "        # --- Epoch Summary ---\n",
    "        if num_optimizer_steps_in_epoch > 0:\n",
    "             avg_loss = total_loss / num_optimizer_steps_in_epoch\n",
    "             avg_Ls = total_Ls / num_batches_processed if num_batches_processed > 0 else 0\n",
    "             avg_Lu = total_Lu / num_batches_processed if num_batches_processed > 0 else 0\n",
    "             avg_Lc = total_Lc / num_batches_processed if num_batches_processed > 0 else 0\n",
    "             print(f\"Epoch {epoch+1} Avg Loss: {avg_loss:.4f} | Avg Ls: {avg_Ls:.4f} | Avg Lu: {avg_Lu:.4f} | Avg Lc: {avg_Lc:.4f}\")\n",
    "        else:\n",
    "             print(f\"Epoch {epoch+1} completed (no optimizer steps performed).\")\n",
    "\n",
    "    return \"EPASS SSL Training Completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Ensure model is on the correct device\n",
    "            model.to(device)\n",
    "            # Use autocast for evaluation if using AMP during training, though usually not needed\n",
    "            # with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits, _ = model(input_ids, attention_mask)\n",
    "\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/dbpedia-ontology/train.csv'\n",
    "test_path = '/kaggle/input/dbpedia-ontology/test.csv'\n",
    "accuracy_percent = 0.0 # Initialize in case of errors before evaluation\n",
    "\n",
    "try:\n",
    "    # --- Load Data ---\n",
    "    train_df_full, test_df = load_data_csv(train_path, test_path)\n",
    "\n",
    "    if NUM_CLASSES <= 0:\n",
    "        raise ValueError(\"Number of classes not determined correctly during data loading.\")\n",
    "\n",
    "    # --- Data Splitting ---\n",
    "    labels_for_split = train_df_full['label'].values\n",
    "    indices = np.arange(len(train_df_full))\n",
    "    n_labeled = max(1, int(len(train_df_full) * LABELED_RATIO))\n",
    "    unique_labels, counts = np.unique(labels_for_split[labels_for_split >= 0], return_counts=True)\n",
    "    can_stratify = len(unique_labels) == NUM_CLASSES and np.all(counts >= 2)\n",
    "\n",
    "    if can_stratify:\n",
    "         print(\"Stratifying labeled/unlabeled split...\")\n",
    "         labeled_idx, unlabeled_idx = train_test_split(\n",
    "             indices, train_size=n_labeled, stratify=labels_for_split, random_state=42\n",
    "         )\n",
    "    else:\n",
    "         print(\"Warning: Cannot stratify. Performing random split...\")\n",
    "         labeled_idx, unlabeled_idx = train_test_split(\n",
    "             indices, train_size=n_labeled, random_state=42\n",
    "         )\n",
    "\n",
    "    labeled_df = train_df_full.iloc[labeled_idx].reset_index(drop=True)\n",
    "    unlabeled_df = train_df_full.iloc[unlabeled_idx].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Total training samples: {len(train_df_full)}\")\n",
    "    print(f\"Labeled samples: {len(labeled_df)}\")\n",
    "    print(f\"Unlabeled samples: {len(unlabeled_df)}\")\n",
    "    print(f\"Test samples: {len(test_df)}\")\n",
    "    print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    print(\"Creating datasets...\")\n",
    "    labeled_dataset = SSLTextDataset(labeled_df['content'].tolist(), labeled_df['label'].tolist(), tokenizer, MAX_LEN, is_labeled=True)\n",
    "    unlabeled_dataset = SSLTextDataset(unlabeled_df['content'].tolist(), [-1]*len(unlabeled_df), tokenizer, MAX_LEN, is_labeled=False)\n",
    "    test_dataset = SSLTextDataset(test_df['content'].tolist(), test_df['label'].tolist(), tokenizer, MAX_LEN, is_labeled=True)\n",
    "\n",
    "    effective_labeled_batch_size = min(BATCH_SIZE, len(labeled_dataset)) if len(labeled_dataset) > 0 else 0\n",
    "    if effective_labeled_batch_size == 0 and len(labeled_dataset) > 0:\n",
    "         effective_labeled_batch_size = 1\n",
    "         print(\"Warning: Calculated labeled batch size is 0, setting to 1.\")\n",
    "    elif len(labeled_dataset) == 0:\n",
    "         print(\"Warning: Labeled dataset is empty. Ls will be 0. Setting labeled loader to None.\")\n",
    "         effective_labeled_batch_size = 0\n",
    "\n",
    "    effective_unlabeled_batch_size = 0\n",
    "    if len(unlabeled_dataset) > 0:\n",
    "         if effective_labeled_batch_size > 0:\n",
    "              unlabeled_multiplier = max(1, round(len(unlabeled_df) / len(labeled_df))) # Use rounding\n",
    "         else: \n",
    "              unlabeled_multiplier = UNLABELED_BATCH_SIZE_MULTIPLIER\n",
    "         effective_unlabeled_batch_size = min(BATCH_SIZE * unlabeled_multiplier, len(unlabeled_dataset))\n",
    "         if effective_unlabeled_batch_size == 0:\n",
    "              effective_unlabeled_batch_size = BATCH_SIZE # Fallback if dataset is very small\n",
    "    else:\n",
    "        print(\"Warning: Unlabeled dataset is empty. Lu, Lc will be 0.\")\n",
    "\n",
    "    print(f\"Using Labeled Batch Size: {effective_labeled_batch_size}\")\n",
    "    print(f\"Using Unlabeled Batch Size: {effective_unlabeled_batch_size}\")\n",
    "\n",
    "    # Create loaders only if batch size is > 0\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=effective_labeled_batch_size, shuffle=True, drop_last=True) if effective_labeled_batch_size > 0 else None\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=effective_unlabeled_batch_size, shuffle=True, drop_last=True) if effective_unlabeled_batch_size > 0 else None\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n",
    "    print(\"Dataloaders created.\")\n",
    "\n",
    "    # --- Initialize Models, Optimizer, Memory Bank ---\n",
    "    print(\"Initializing models...\")\n",
    "    # Reload base models to ensure they are not on device yet\n",
    "    base_bert_model_student = BertModel.from_pretrained(PRETRAINED_MODEL)\n",
    "    student_model = EPASSModel(base_bert_model_student, NUM_CLASSES, BERT_OUTPUT_DIM, PROJECTOR_DIM, EMBEDDING_DIM, NUM_PROJECTORS).to(DEVICE)\n",
    "    \n",
    "    ema_base_bert_model = BertModel.from_pretrained(PRETRAINED_MODEL)\n",
    "    ema_model = EPASSModel(ema_base_bert_model, NUM_CLASSES, BERT_OUTPUT_DIM, PROJECTOR_DIM, EMBEDDING_DIM, NUM_PROJECTORS).to(DEVICE)\n",
    "\n",
    "    for param_q, param_k in zip(student_model.parameters(), ema_model.parameters()):\n",
    "        param_k.data.copy_(param_q.data)\n",
    "        param_k.requires_grad = False\n",
    "\n",
    "    optimizer = optim.AdamW(student_model.parameters(), lr=LR)\n",
    "    criterion_ce = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    criterion_ce_noreduction = nn.CrossEntropyLoss(reduction='none').to(DEVICE)\n",
    "\n",
    "    # <<< Ensure Memory Bank is initialized AFTER NUM_CLASSES is determined >>>\n",
    "    memory_bank = MemoryBank(MEM_BANK_SIZE, EMBEDDING_DIM, NUM_CLASSES, DEVICE)\n",
    "    print(\"Models and optimizer initialized.\")\n",
    "\n",
    "    # --- Start Training ---\n",
    "    print(\"Starting EPASS SSL Training...\")\n",
    "    epass_results = train_ssl_model(\n",
    "        student_model, ema_model, memory_bank,\n",
    "        labeled_loader, unlabeled_loader,\n",
    "        optimizer, criterion_ce, criterion_ce_noreduction,\n",
    "        DEVICE, EPOCHS, MOMENTUM, TEMPERATURE, CONFIDENCE_THRESHOLD,\n",
    "        LAMBDA_U, LAMBDA_C, accumulation_steps=GRADIENT_ACCUMULATION_STEPS\n",
    "    )\n",
    "    print(epass_results)\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    print(\"Evaluating EMA model on test set...\")\n",
    "    accuracy, _, _ = evaluate_model(ema_model, test_loader, DEVICE)\n",
    "    accuracy_percent = accuracy * 100\n",
    "    print(f\"Final EMA Model Test Accuracy: {accuracy_percent:.2f}%\")\n",
    "\n",
    "    # --- Save Model ---\n",
    "    torch.save(ema_model.state_dict(), \"/kaggle/working/epass_ema_model_state_dict.pth\")\n",
    "    print(\"EMA Model state dict saved.\")\n",
    "\n",
    "except Exception as main_e:\n",
    "    print(f\"An error occurred during main execution: {main_e}\")\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Clean up CUDA cache if needed\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Display Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final EMA Model Test Accuracy: {accuracy_percent:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 20100,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}