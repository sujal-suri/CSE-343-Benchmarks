{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPASS Implementation - RESUME Training\n",
    "\n",
    "This notebook **resumes** the EPASS training from a previously saved checkpoint (`epass_tinyimagenet_best.pth`).\n",
    "\n",
    "**Goal:** Continue training for an additional number of epochs.\n",
    "\n",
    "**Assumptions:**\n",
    "*   The `epass_tinyimagenet_best.pth` file exists in the current directory and contains the state dictionary of the best student model from the previous run.\n",
    "*   The configuration parameters (architecture, batch sizes, learning rate, etc.) are kept consistent with the initial run.\n",
    "*   The data has already been downloaded and the validation set reorganized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "import gc # Garbage collector\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models, datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility (keep consistent if possible, though data shuffling will differ)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration (MUST match initial run, except for epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Configuration\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Parameters from the initial run (KEEP THESE THE SAME) ---\n",
    "DATA_DIR = 'tiny-imagenet-200'\n",
    "NUM_CLASSES = 200\n",
    "IMG_SIZE = 64 \n",
    "INPUT_SIZE = 64\n",
    "labeled_ratio = 0.1  \n",
    "batch_size = 128      \n",
    "mu = 3               \n",
    "labeled_bs = batch_size // (mu + 1)\n",
    "unlabeled_bs = batch_size - labeled_bs\n",
    "confidence_threshold = 0.95 \n",
    "num_projectors = 3   \n",
    "projection_dim = 128 \n",
    "learning_rate = 0.03 # Initial LR (scheduler will adjust)\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "ema_decay = 0.999    \n",
    "lambda_u = 1.0       \n",
    "lambda_c = 0.1       \n",
    "contrastive_temp = 0.1 \n",
    "\n",
    "# --- Parameters for Resumed Run ---\n",
    "start_epoch = 35 # Epoch number the previous run finished at\n",
    "additional_epochs = 35 # How many MORE epochs to run\n",
    "total_epochs = start_epoch + additional_epochs # The final target epoch number\n",
    "checkpoint_path = 'epass_tinyimagenet_best.pth' # Path to saved model\n",
    "previous_best_accuracy = 37.16 # Best accuracy from the previous run\n",
    "\n",
    "print(f\"Resuming training from epoch {start_epoch}\")\n",
    "print(f\"Running for {additional_epochs} additional epochs (up to epoch {total_epochs})\")\n",
    "print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "print(f\"Previous best accuracy: {previous_best_accuracy}%\")\n",
    "\n",
    "# Print derived batch sizes\n",
    "print(f\"Total Batch Size: {batch_size}\")\n",
    "print(f\"Labeled Batch Size: {labeled_bs}\")\n",
    "print(f\"Unlabeled Batch Size: {unlabeled_bs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Download and Preparation\n",
    "(Should already be done, but run to confirm paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "     raise FileNotFoundError(f\"Data directory '{DATA_DIR}' not found. Please run the initial data download cell first.\")\n",
    "else:\n",
    "    print(\"Tiny ImageNet directory exists.\")\n",
    "\n",
    "# Define training and validation data paths\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train') \n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')\n",
    "reorganized_val_dir = os.path.join(VALID_DIR, 'organized')\n",
    "\n",
    "# Check if validation set is reorganized\n",
    "if not os.path.exists(reorganized_val_dir):\n",
    "    # Attempt reorganization if needed (copy logic from previous notebook)\n",
    "    print(\"Reorganizing validation set...\")\n",
    "    # ... [Include the validation set reorganization code here if necessary] ...\n",
    "    # For brevity, assuming it's already done. If not, paste the code from the previous notebook.\n",
    "    # Ensure VALID_DIR_LOADER is set correctly after reorganization.\n",
    "    VALID_DIR_LOADER = reorganized_val_dir # Adjust if needed\n",
    "    if not os.path.exists(VALID_DIR_LOADER):\n",
    "         raise FileNotFoundError(\"Validation directory reorganized path does not exist. Reorganization might have failed.\")\n",
    "    print(\"Validation set reorganized.\")\n",
    "else:\n",
    "    print(\"Using previously reorganized validation set:\", reorganized_val_dir)\n",
    "    VALID_DIR_LOADER = reorganized_val_dir\n",
    "\n",
    "# --- Load Class Names --- \n",
    "# (Same as before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Augmentations and Datasets\n",
    "(Recreate datasets and dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization values\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Weak Augmentation \n",
    "transform_weak = T.Compose([\n",
    "    T.RandomResizedCrop(INPUT_SIZE, scale=(0.2, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Strong Augmentation\n",
    "transform_strong = T.Compose([\n",
    "    T.RandomResizedCrop(INPUT_SIZE, scale=(0.2, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandAugment(num_ops=2, magnitude=10),\n",
    "    T.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Standard transform for validation\n",
    "transform_val = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# --- Custom Datasets --- (Same classes as before)\n",
    "class TinyImageNetLabeled(Dataset):\n",
    "    def __init__(self, root, indices, transform):\n",
    "        temp_dataset = datasets.ImageFolder(root)\n",
    "        self.base_path = root\n",
    "        self.samples = [(temp_dataset.samples[i][0], temp_dataset.targets[i]) for i in indices]\n",
    "        self.transform = transform\n",
    "        self.loader = temp_dataset.loader\n",
    "        del temp_dataset\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "class TinyImageNetUnlabeled(Dataset):\n",
    "    def __init__(self, root, indices, transform_weak, transform_strong):\n",
    "        temp_dataset = datasets.ImageFolder(root)\n",
    "        self.base_path = root\n",
    "        self.samples = [temp_dataset.samples[i][0] for i in indices]\n",
    "        self.transform_weak = transform_weak\n",
    "        self.transform_strong = transform_strong\n",
    "        self.loader = temp_dataset.loader\n",
    "        del temp_dataset\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        img = self.loader(path)\n",
    "        img_weak = self.transform_weak(img)\n",
    "        img_strong = self.transform_strong(img)\n",
    "        return img_weak, img_strong\n",
    "\n",
    "# --- Recreate Labeled/Unlabeled Split --- \n",
    "# NOTE: The split will be different due to shuffling unless the indices were saved.\n",
    "# Using the same *procedure* ensures the dataset sizes are correct.\n",
    "print(\"Recreating train/validation datasets...\")\n",
    "base_train_dataset_info = datasets.ImageFolder(TRAIN_DIR)\n",
    "val_dataset = datasets.ImageFolder(VALID_DIR_LOADER, transform=transform_val)\n",
    "num_train_samples = len(base_train_dataset_info)\n",
    "num_labeled_samples = int(labeled_ratio * num_train_samples)\n",
    "print(f\"Total training samples: {num_train_samples}\")\n",
    "print(f\"Using {num_labeled_samples} labeled samples ({labeled_ratio*100}%)\")\n",
    "\n",
    "targets = np.array(base_train_dataset_info.targets)\n",
    "labeled_indices = []\n",
    "unlabeled_indices = []\n",
    "samples_per_class = num_labeled_samples // NUM_CLASSES\n",
    "if samples_per_class == 0:\n",
    "    raise ValueError(f\"labeled_ratio ({labeled_ratio}) is too small for {NUM_CLASSES} classes.\")\n",
    "print(f\"Aiming for {samples_per_class} labeled samples per class.\")\n",
    "\n",
    "np.random.seed(seed) # Ensure same split if seed is same\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_indices = np.where(targets == i)[0]\n",
    "    np.random.shuffle(class_indices)\n",
    "    labeled_indices.extend(class_indices[:samples_per_class])\n",
    "    unlabeled_indices.extend(class_indices[samples_per_class:])\n",
    "\n",
    "num_labeled_actual = len(labeled_indices)\n",
    "num_unlabeled_actual = len(unlabeled_indices)\n",
    "print(f\"Actual labeled samples: {num_labeled_actual}\")\n",
    "print(f\"Actual unlabeled samples: {num_unlabeled_actual}\")\n",
    "\n",
    "print(\"Creating labeled/unlabeled datasets...\")\n",
    "labeled_dataset = TinyImageNetLabeled(TRAIN_DIR, labeled_indices, transform=transform_weak)\n",
    "unlabeled_dataset = TinyImageNetUnlabeled(TRAIN_DIR, unlabeled_indices, \n",
    "                                          transform_weak=transform_weak, \n",
    "                                          transform_strong=transform_strong)\n",
    "del base_train_dataset_info\n",
    "gc.collect()\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "print(\"Creating DataLoaders...\")\n",
    "num_iterations = len(unlabeled_dataset) // unlabeled_bs\n",
    "if num_iterations == 0:\n",
    "    raise ValueError(f\"Unlabeled batch size ({unlabeled_bs}) too large.\")\n",
    "\n",
    "dataloader_num_workers = 2 if use_cuda else 0\n",
    "labeled_loader = DataLoader(\n",
    "    labeled_dataset, batch_size=labeled_bs, shuffle=True,\n",
    "    num_workers=dataloader_num_workers, pin_memory=use_cuda, drop_last=True)\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_dataset, batch_size=unlabeled_bs, shuffle=True,\n",
    "    num_workers=dataloader_num_workers, pin_memory=use_cuda, drop_last=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=dataloader_num_workers, pin_memory=use_cuda)\n",
    "\n",
    "print(f\"Labeled loader batches per epoch: {len(labeled_loader)}\")\n",
    "print(f\"Unlabeled loader batches per epoch: {len(unlabeled_loader)}\")\n",
    "print(f\"Validation loader batches: {len(val_loader)}\")\n",
    "print(f\"Number of iterations per epoch: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definition (Encoder + EPASS Projector + Classifier)\n",
    "(Identical definition as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPProjector(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "def create_modified_resnet18(pretrained=False): # Set pretrained=False initially\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    # We will modify the final fc layer inside EPASS_Model\n",
    "    return model\n",
    "\n",
    "class EPASS_Model(nn.Module):\n",
    "    def __init__(self, backbone, num_classes, num_projectors, projection_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        if hasattr(backbone, 'fc'):\n",
    "             self.feature_dim = backbone.fc.in_features\n",
    "             self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "             self.feature_dim = 512\n",
    "        print(f\"Backbone feature dimension: {self.feature_dim}\")\n",
    "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
    "        self.num_projectors = num_projectors\n",
    "        self.projectors = nn.ModuleList([\n",
    "            MLPProjector(self.feature_dim, output_dim=projection_dim)\n",
    "            for _ in range(num_projectors)\n",
    "        ])\n",
    "    def forward(self, x, return_features=False, return_projection=False):\n",
    "        features = self.backbone(x)\n",
    "        logits = self.classifier(features)\n",
    "        if return_projection:\n",
    "            projected_embeddings = []\n",
    "            for projector in self.projectors:\n",
    "                projected_embeddings.append(projector(features))\n",
    "            ensembled_embedding = torch.mean(torch.stack(projected_embeddings, dim=0), dim=0)\n",
    "            ensembled_embedding = F.normalize(ensembled_embedding, dim=1)\n",
    "            if return_features:\n",
    "                return logits, features, ensembled_embedding\n",
    "            else:\n",
    "                return logits, ensembled_embedding\n",
    "        else:\n",
    "            if return_features:\n",
    "                return logits, features\n",
    "            else:\n",
    "                return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Instantiation and Loading State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating student and teacher models...\")\n",
    "backbone_student = create_modified_resnet18(pretrained=False) # Arch only\n",
    "student_model = EPASS_Model(backbone_student, NUM_CLASSES, num_projectors, projection_dim).to(device)\n",
    "\n",
    "backbone_teacher = create_modified_resnet18(pretrained=False) # Arch only\n",
    "teacher_model = EPASS_Model(backbone_teacher, NUM_CLASSES, num_projectors, projection_dim).to(device)\n",
    "\n",
    "# --- Load the saved state dictionary --- \n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading state from {checkpoint_path}...\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    # Load student state\n",
    "    student_model.load_state_dict(checkpoint) # Assumes saved file is just the state_dict\n",
    "    print(\"Student model state loaded.\")\n",
    "    \n",
    "    # Initialize teacher with the loaded student state\n",
    "    print(\"Initializing teacher model from loaded student state...\")\n",
    "    for param_teacher, param_student in zip(teacher_model.parameters(), student_model.parameters()):\n",
    "        param_teacher.data.copy_(param_student.data)\n",
    "        param_teacher.requires_grad = False\n",
    "    print(\"Teacher model initialized.\")\n",
    "\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}. Cannot resume training.\")\n",
    "\n",
    "print(\"Models ready for resumed training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Loss Functions, Optimizer, and Scheduler (Re-initialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions (Same as before)\n",
    "criterion_s = nn.CrossEntropyLoss()\n",
    "criterion_u = nn.CrossEntropyLoss(reduction='none')\n",
    "def contrastive_loss(emb_student_strong, emb_teacher_weak, temperature):\n",
    "    sim = torch.sum(emb_student_strong * emb_teacher_weak, dim=1)\n",
    "    loss = -sim / temperature\n",
    "    return loss.mean()\n",
    "\n",
    "# Optimizer (Linked to the student model with loaded weights)\n",
    "optimizer = optim.SGD(student_model.parameters(), \n",
    "                      lr=learning_rate, \n",
    "                      momentum=momentum, \n",
    "                      weight_decay=weight_decay,\n",
    "                      nesterov=True)\n",
    "\n",
    "# Scheduler \n",
    "# IMPORTANT: T_max should be based on the *total* number of epochs (original + additional)\n",
    "total_train_steps = num_iterations * total_epochs\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_train_steps)\n",
    "\n",
    "# --- Advance the scheduler --- \n",
    "# We need to step the scheduler forward to where it would have been at the start_epoch\n",
    "steps_to_advance = start_epoch * num_iterations\n",
    "print(f\"Advancing scheduler by {steps_to_advance} steps...\")\n",
    "# Temporarily set the initial LR in the optimizer to avoid warnings during fast-forwarding\n",
    "initial_lr = optimizer.param_groups[0]['lr']\n",
    "for _ in tqdm(range(steps_to_advance), desc=\"Fast-forwarding scheduler\"):\n",
    "    scheduler.step()\n",
    "\n",
    "# Restore the original LR in the optimizer (scheduler.step() modifies it)\n",
    "# The *next* scheduler.step() in the training loop will apply the correct decayed LR.\n",
    "# optimizer.param_groups[0]['lr'] = initial_lr \n",
    "# Correction: No, scheduler.step() correctly sets the LR for the *next* step.\n",
    "# We want the LR that scheduler arrived at after advancing.\n",
    "current_lr = optimizer.param_groups[0]['lr']\n",
    "print(f\"Scheduler advanced. Current LR for next step: {current_lr:.1e}\")\n",
    "\n",
    "# EMA Update Function (Same as before)\n",
    "@torch.no_grad()\n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop Function (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(student_model, teacher_model, labeled_loader, unlabeled_loader, optimizer, scheduler, epoch, num_iterations, total_epochs):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    total_loss_s, total_loss_u, total_loss_c, total_loss = 0.0, 0.0, 0.0, 0.0\n",
    "    mask_ratio_acc = 0.0\n",
    "    labeled_processed, unlabeled_processed = 0, 0\n",
    "\n",
    "    labeled_iter = iter(labeled_loader)\n",
    "    unlabeled_iter = iter(unlabeled_loader)\n",
    "    \n",
    "    # Use total_epochs in the progress bar description\n",
    "    pbar = tqdm(range(num_iterations), desc=f\"Epoch {epoch+1}/{total_epochs}\") \n",
    "\n",
    "    for i in pbar:\n",
    "        try:\n",
    "            images_l, targets_l = next(labeled_iter)\n",
    "        except StopIteration:\n",
    "            labeled_iter = iter(labeled_loader)\n",
    "            images_l, targets_l = next(labeled_iter)\n",
    "\n",
    "        try:\n",
    "            images_uw, images_us = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "             print(\"Warning: Unlabeled loader exhausted unexpectedly.\")\n",
    "             break \n",
    "        \n",
    "        images_l, targets_l = images_l.to(device), targets_l.to(device)\n",
    "        images_uw, images_us = images_uw.to(device), images_us.to(device)\n",
    "\n",
    "        bs_l = images_l.shape[0]\n",
    "        bs_u = images_uw.shape[0]\n",
    "\n",
    "        logits_l = student_model(images_l)\n",
    "        loss_s = criterion_s(logits_l, targets_l)\n",
    "\n",
    "        logits_us, emb_us = student_model(images_us, return_projection=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits_uw, emb_uw = teacher_model(images_uw, return_projection=True)\n",
    "\n",
    "        pseudo_label = torch.softmax(logits_uw, dim=-1)\n",
    "        max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "        mask = max_probs.ge(confidence_threshold).float()\n",
    "        loss_u_all = criterion_u(logits_us, targets_u)\n",
    "        loss_u = (torch.sum(loss_u_all * mask) / (mask.sum() + 1e-6))\n",
    "        mask_ratio = mask.mean().item()\n",
    "\n",
    "        loss_c = contrastive_loss(emb_us, emb_uw, contrastive_temp)\n",
    "        \n",
    "        loss_u_item = 0.0 if torch.isnan(loss_u) or torch.isinf(loss_u) else loss_u.item()\n",
    "        total_batch_loss = loss_s + lambda_u * loss_u + lambda_c * loss_c if loss_u_item != 0.0 else loss_s + lambda_c * loss_c\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "\n",
    "        global_step = epoch * num_iterations + i # Global step relative to start of training (epoch 0)\n",
    "        update_ema_variables(student_model, teacher_model, ema_decay, global_step)\n",
    "\n",
    "        loss_s_item = loss_s.item()\n",
    "        loss_c_item = loss_c.item()\n",
    "        total_loss_s += loss_s_item * bs_l\n",
    "        total_loss_u += loss_u_item * bs_u\n",
    "        total_loss_c += loss_c_item * bs_u\n",
    "        total_loss += total_batch_loss.item() \n",
    "        mask_ratio_acc += mask_ratio\n",
    "        labeled_processed += bs_l\n",
    "        unlabeled_processed += bs_u\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'Ls': f'{loss_s_item:.4f}', 'Lu': f'{loss_u_item:.4f}', 'Lc': f'{loss_c_item:.4f}',\n",
    "            'Mask': f'{mask_ratio:.2f}', 'LR': f'{optimizer.param_groups[0][\"lr\"]:.1e}'\n",
    "        })\n",
    "\n",
    "    avg_loss_s = total_loss_s / labeled_processed if labeled_processed > 0 else 0\n",
    "    avg_loss_u = total_loss_u / unlabeled_processed if unlabeled_processed > 0 else 0\n",
    "    avg_loss_c = total_loss_c / unlabeled_processed if unlabeled_processed > 0 else 0\n",
    "    avg_loss = (total_loss_s + total_loss_u + total_loss_c) / (labeled_processed + unlabeled_processed) if (labeled_processed + unlabeled_processed) > 0 else 0\n",
    "    avg_mask_ratio = mask_ratio_acc / num_iterations if num_iterations > 0 else 0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{total_epochs} Summary: Avg Loss: {avg_loss:.4f}, Ls: {avg_loss_s:.4f}, Lu: {avg_loss_u:.4f}, Lc: {avg_loss_c:.4f}, Mask Ratio: {avg_mask_ratio:.4f}\")\n",
    "    return avg_loss, avg_mask_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation Function (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=\"Evaluating\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images, return_projection=False)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            pbar.set_postfix({'Val Acc': f'{(100 * correct / total):.2f}%'})\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Resumed Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "mask_ratios = []\n",
    "best_val_accuracy = previous_best_accuracy # Initialize with previous best\n",
    "best_epoch = start_epoch # Assume the loaded model is the best initially\n",
    "\n",
    "start_time_resume = dt.now()\n",
    "print(f\"Resuming training at {start_time_resume}...\")\n",
    "\n",
    "if use_cuda:\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# The loop now starts from start_epoch and goes up to total_epochs\n",
    "for epoch in range(start_epoch, total_epochs):\n",
    "    # Train\n",
    "    # Pass total_epochs to the training function for correct global step calculation\n",
    "    train_loss, mask_ratio = train_one_epoch(student_model, teacher_model, labeled_loader, unlabeled_loader, \n",
    "                                             optimizer, scheduler, epoch, num_iterations, total_epochs) \n",
    "    train_losses.append(train_loss) # Store losses for this resumed session\n",
    "    mask_ratios.append(mask_ratio)\n",
    "\n",
    "    # Evaluate\n",
    "    val_loss, val_accuracy = evaluate(student_model, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Save best model (only if current accuracy exceeds the overall best)\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_epoch = epoch + 1 # Record the epoch number (1-based)\n",
    "        torch.save(student_model.state_dict(), checkpoint_path) # Overwrite the previous best\n",
    "        print(f\"*** Best model saved with accuracy: {best_val_accuracy:.2f}% (Epoch {best_epoch}) ***\")\n",
    "        \n",
    "    # Optional: Clear cache\n",
    "    if use_cuda and (epoch + 1) % 5 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "end_time_resume = dt.now()\n",
    "print(f\"\\nResumed training finished at {end_time_resume}. Duration: {end_time_resume - start_time_resume}\")\n",
    "print(f\"Overall Best Validation Accuracy: {best_val_accuracy:.2f}% (achieved at Epoch {best_epoch})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plotting Results (for the resumed part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for the resumed epochs only\n",
    "epochs_resumed_range = range(start_epoch + 1, total_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_resumed_range, train_losses, label='Avg Training Loss (Resumed)')\n",
    "plt.plot(epochs_resumed_range, val_losses, label='Validation Loss (Resumed)')\n",
    "plt.title(f'Losses (Epochs {start_epoch+1}-{total_epochs})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_resumed_range, val_accuracies, label='Validation Accuracy (Resumed)', color='green')\n",
    "plt.axhline(y=previous_best_accuracy, color='r', linestyle='--', label=f'Previous Best ({previous_best_accuracy:.2f}%)')\n",
    "plt.title(f'Validation Accuracy (Epochs {start_epoch+1}-{total_epochs})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs_resumed_range, mask_ratios, label='Mask Ratio (Resumed)', color='orange')\n",
    "plt.title(f'Mask Ratio (Epochs {start_epoch+1}-{total_epochs})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Ratio')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}