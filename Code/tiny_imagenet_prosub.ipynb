{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-_A62UJf89x"
      },
      "source": [
        "TODO:\n",
        "\n",
        "*   Create the dataloader/Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1_6b3B9f30l"
      },
      "source": [
        "References:\n",
        "\n",
        "---\n",
        "\n",
        "1.   https://medium.com/the-owl/extracting-output-from-intermediate-layer-in-any-pretrained-model-the-pytorch-way-b201926a1eec\n",
        "\n",
        "2. Sohn, Kihyuk, et al. \"Fixmatch: Simplifying semi-supervised learning with consistency and confidence.\" Advances in neural information processing systems 33 (2020): 596-608.\n",
        "\n",
        "3. Wallin, Erik, et al. \"ProSub: Probabilistic Open-Set Semi-supervised Learning with Subspace-Based Out-of-Distribution Detection.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tD8KFrzXfzn3"
      },
      "outputs": [],
      "source": [
        "\"Required Imports\"\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torchvision.models import resnet50, resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from itertools import compress\n",
        "from torchvision.models._utils import IntermediateLayerGetter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xfPvoZ8CgHeZ"
      },
      "outputs": [],
      "source": [
        "\"For code reproducability\"\n",
        "MANUAL_SEED = 42\n",
        "torch.manual_seed(MANUAL_SEED)\n",
        "torch.cuda.manual_seed(MANUAL_SEED)\n",
        "np.random.seed(MANUAL_SEED)\n",
        "random.seed(MANUAL_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of0SR1bKgKFU"
      },
      "source": [
        "Dataset description:\n",
        "*   Contains a total of 1,00,000 images\n",
        "*   200 Classes each class contains 500 Images\n",
        "*   resolution of image is 64x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHTDC6vlgL4c",
        "outputId": "c5f81a29-0c10-4889-a030-c18a80b23e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594 (from 1)\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 17.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Updating files: 100% (120206/120206), done.\n"
          ]
        }
      ],
      "source": [
        "\"Source: https://github.com/seshuad/IMagenet\"\n",
        "\"Extracting the ImageNet folder out of some random repository I found on github\"\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! mv IMagenet/tiny-imagenet-200 ./\n",
        "! rm -r IMagenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EX1B5JgUjmvK"
      },
      "outputs": [],
      "source": [
        "dataset_path = './tiny-imagenet-200'\n",
        "dataset_classes = sorted(os.listdir(os.path.join(dataset_path, 'train')))\n",
        "\n",
        "ID_MASK = np.concatenate((np.ones(100, dtype=bool), np.zeros(100, dtype=bool)))\n",
        "OOD_MASK = ~ID_MASK\n",
        "\n",
        "OOD_CLASSES = list(compress(dataset_classes, OOD_MASK))\n",
        "ID_CLASSES = list(compress(dataset_classes, ID_MASK))\n",
        "ID_classes = ID_CLASSES\n",
        "OOD_classes = OOD_CLASSES\n",
        "ID_OOD_ratio = len(ID_classes)/len(OOD_classes)\n",
        "\n",
        "ltoi = {l: i for i, l in enumerate(ID_CLASSES)}\n",
        "itol = {i: l for i, l in enumerate(ID_CLASSES)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFqLzweWnUxg",
        "outputId": "70927840-164d-41ba-cfc5-edfbde38405d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Labeled = 10000, # Unlabeled = 90000\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "\n",
        "train_Labeled = []\n",
        "train_Unlabeled = []\n",
        "\n",
        "all_labeled = []\n",
        "all_unlabeled = []\n",
        "\n",
        "for label in os.listdir(train_path):\n",
        "    image_dir = os.path.join(train_path, label, 'images')\n",
        "    image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir)]\n",
        "\n",
        "    if label in OOD_classes:\n",
        "        all_unlabeled.extend(image_paths)\n",
        "    else:\n",
        "        all_labeled.extend([(img_path, ltoi[label]) for img_path in image_paths])\n",
        "\n",
        "np.random.shuffle(all_labeled)\n",
        "np.random.shuffle(all_unlabeled)\n",
        "\n",
        "train_Labeled = all_labeled[:10_000]\n",
        "remaining_labeled = all_labeled[10_000:]\n",
        "train_Unlabeled = all_unlabeled + [x[0] for x in remaining_labeled]  # Only image paths for unlabeled\n",
        "\n",
        "print(f\"# Labeled = {len(train_Labeled)}, # Unlabeled = {len(train_Unlabeled)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNf5_b3psl3W",
        "outputId": "f4b9a3d2-d744-4bef-a633-4095f1ba09ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistic of the Train Data\n",
            "Number of ID classes are: 100, Number of OOD classes are: 100\n",
            "Number of Labeled Samples: 10000, Number of UnLabeled Samples: 90000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Statistic of the Train Data\")\n",
        "print(f\"Number of ID classes are: {len(ID_classes)}, Number of OOD classes are: {len(OOD_classes)}\")\n",
        "print(f\"Number of Labeled Samples: {len(train_Labeled)}, Number of UnLabeled Samples: {len(train_Unlabeled)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2CorXFA0tdrc"
      },
      "outputs": [],
      "source": [
        "val_path = os.path.join(dataset_path, 'val', 'images')\n",
        "annotation_path = './tiny-imagenet-200/val/val_annotations.txt'\n",
        "\n",
        "val_data = []\n",
        "with open(annotation_path, 'r') as f:\n",
        "    val_annotations = [(line.split('\\t')[0], line.split('\\t')[1]) for line in f.readlines()]\n",
        "\n",
        "for img_name, label in val_annotations:\n",
        "    img_path = os.path.join(val_path, img_name)\n",
        "    val_data.append((img_path, ltoi.get(label, -1))) # Returning -1 for labels not ID classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SVLoFFPR7Jvd"
      },
      "outputs": [],
      "source": [
        "class TinyImageNet(Dataset):\n",
        "    def __init__(self, data:list, labeled=True, is_val=False):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.is_labeled = labeled\n",
        "        self.is_val = is_val\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    \"For some reasons it takes all ram while running it transform\"\n",
        "    def strong_augment(self, image):\n",
        "        strong_transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply([\n",
        "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
        "            ], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        return strong_transform(image)\n",
        "\n",
        "    def weak_augment(self, image):\n",
        "        weak_transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "            transforms.ToTensor()\n",
        "                            ])\n",
        "        return weak_transform(image)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if(self.is_val):\n",
        "            X, y = self.data[idx]\n",
        "            img = Image.open(X).convert('RGB')\n",
        "            img = self.weak_augment(img)\n",
        "            return img, torch.tensor(y)\n",
        "        if(self.is_labeled):\n",
        "            X, y = self.data[idx]\n",
        "            img = Image.open(X).convert('RGB')\n",
        "            alpha_img = self.weak_augment(img)\n",
        "            return alpha_img, torch.tensor(y)\n",
        "        else:\n",
        "            X = self.data[idx]\n",
        "            img = Image.open(X).convert('RGB')\n",
        "            alpha_img, beta_img = self.weak_augment(img), self.strong_augment(img)\n",
        "            return alpha_img, beta_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RRG_EyWAJQ-m"
      },
      "outputs": [],
      "source": [
        "unlabeled_batch_size = 9*128\n",
        "batch_size = 128\n",
        "test_size = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yWrDXCOZ1eCv"
      },
      "outputs": [],
      "source": [
        "train_Labeled_dataset = TinyImageNet(train_Labeled, labeled=True)\n",
        "train_Unlabeled_dataset = TinyImageNet(train_Unlabeled, labeled=False)\n",
        "val_dataset = TinyImageNet(val_data, labeled=True, is_val=True)\n",
        "train_labeled_dataloader = DataLoader(train_Labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "train_unlabeled_dataloader = DataLoader(train_Unlabeled_dataset, batch_size=unlabeled_batch_size, shuffle=True, drop_last=True)\n",
        "test_labeled_dataloader = DataLoader(val_dataset, batch_size=test_size, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "df00f34e3b68417d9e719f8e1c234018",
            "5de9954b209d428691e0570ab50405cf",
            "70000964998e4280914b7952d2023a6c",
            "e85d72cb905b42808d964ffafec45746",
            "469c4128f79b45dcb5d1e1cfe4db6510",
            "57201124bf684033a9140e48e2f36de6",
            "3ecfb767a6554ad09e3b14c5869c078f",
            "de810702cdd94a218509e4ced6965bd5",
            "27e67008b05a486887639009ad2b3c1a",
            "e3824b1fb8c54a749ef8ab5f0e7676d6",
            "03af46f2574f453f9cff091041cc7627"
          ]
        },
        "id": "XbmeztqL2qEf",
        "outputId": "5b6d13d1-2db5-41cb-d1ee-c6386cc8647f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df00f34e3b68417d9e719f8e1c234018"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import timm\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(in_f, out_f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "feature_dim = 200\n",
        "backbone = timm.create_model('resnet34', pretrained=True)\n",
        "backbone.fc = nn.Linear(backbone.fc.in_features, feature_dim)\n",
        "classifier = Classifier(feature_dim, 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "efkj6ceo_6xT"
      },
      "outputs": [],
      "source": [
        "def get_batch_mean(Z, y, num_classes, feature_dim, batch_size, device):\n",
        "    sums = torch.zeros(num_classes, feature_dim, dtype=Z_l.dtype, device=device)\n",
        "    counts = torch.zeros(num_classes, dtype=torch.float, device=device)\n",
        "    sums = sums.index_add(0, y_l, Z_l, alpha=1)\n",
        "    ones = torch.ones(batch_size, dtype=torch.float, device=device)\n",
        "    counts = counts.index_add(0, y_l, ones)\n",
        "    counts[counts == 0] = 1.0\n",
        "    avg_values = sums / counts.unsqueeze(1)\n",
        "    return avg_values\n",
        "\n",
        "\n",
        "def subspace_score(Z, batch_means):\n",
        "    \"\"\"\n",
        "    Z: (batch_size, feature_dim)\n",
        "    batch_means: (num_classes, feature_dim)\n",
        "    Returns:\n",
        "        cosine similarity between Z and its projection on the subspace\n",
        "        spanned by batch_means — shape (batch_size, 1)\n",
        "    \"\"\"\n",
        "    Q, _ = torch.linalg.qr(batch_means.T)\n",
        "    proj_Z = Z @ Q @ Q.T\n",
        "    cos_sim = F.cosine_similarity(Z, proj_Z, dim=1).clamp(0, 1)\n",
        "    return cos_sim.unsqueeze(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vWRwgHxRJ7Qn"
      },
      "outputs": [],
      "source": [
        "\"Taken from the code given by the authors... \"\n",
        "def beta_pdf(x, alpha, beta, loc=0.0, scale=1.0):\n",
        "    x = (x - loc) / scale\n",
        "    alpha = torch.as_tensor(alpha, dtype=torch.float32, device=x.device)\n",
        "    beta = torch.as_tensor(beta, dtype=torch.float32, device=x.device)\n",
        "    scale = torch.as_tensor(scale, dtype=torch.float32, device=x.device)\n",
        "    def xlogy(a, b):\n",
        "        return torch.where(a == 0, torch.zeros_like(b), a * torch.log(b + 1e-10))\n",
        "    def xlog1py(a, y):\n",
        "        return torch.where(a == 0, torch.zeros_like(y), a * torch.log1p(y + 1e-10))\n",
        "\n",
        "    log_unnormalized = xlogy(alpha - 1.0, x) + xlog1py(beta - 1.0, -x)\n",
        "    log_normalization = torch.lgamma(alpha) + torch.lgamma(beta) - torch.lgamma(alpha + beta)\n",
        "    log_prob = log_unnormalized - log_normalization\n",
        "    log_prob = torch.where((x >= 0) & (x <= 1), log_prob, torch.tensor(float('-inf'), device=x.device))\n",
        "\n",
        "    return torch.exp(log_prob) / scale\n",
        "\n",
        "def update_beta_parameters(w_id, w_ood, s_l, s_u ,alpha_id, beta_id, alpha_ood, beta_ood, l):\n",
        "    # Detaching from computational graph so that it won't cause some bullshit error\n",
        "    w_id = w_id.squeeze(1).detach(); w_ood = w_ood.squeeze(1).detach()\n",
        "    s_l = s_l.squeeze(1).detach(); s_u = s_u.squeeze(1).detach()\n",
        "    nu_id = torch.sum(s_l) + torch.dot(w_id, s_u)/(s_l.size(0) + torch.sum(w_id))\n",
        "    sigma2_id = (torch.sum(s_l - nu_id)**2 + torch.dot(w_id, (s_u - nu_id)**2))/(s_l.size(0) + torch.sum(w_id))\n",
        "\n",
        "    nu_ood = torch.dot(w_ood, s_u)/(torch.sum(w_ood))\n",
        "    sigma2_ood = torch.dot(w_ood, (s_u - nu_id)**2)/((torch.sum(w_ood)))\n",
        "\n",
        "    _alpha_id = nu_id*((nu_id*(1-nu_id))/sigma2_id - 1)\n",
        "    _alpha_ood = nu_ood*((nu_ood*(1-nu_ood))/sigma2_ood - 1)\n",
        "    _beta_id = (1 - nu_id)*((nu_id*(1-nu_id))/sigma2_id - 1)\n",
        "    _beta_ood = (1 - nu_ood)*((nu_ood*(1-nu_ood))/sigma2_ood - 1)\n",
        "\n",
        "    return alpha_id*l + (1 - l)*_alpha_id, beta_id*l + (1 - l)*_beta_id, alpha_ood*l + (1 - l)*_alpha_ood, beta_ood*l + (1 - l)*_beta_ood\n",
        "\n",
        "def get_p_id(s, alpha_id, beta_id, alpha_ood, beta_ood, pi=1.0):\n",
        "    \"\"\"\n",
        "    Compute the ID probability using Beta PDFs instead of torch.distributions.Beta,\n",
        "    following the formulation in the paper (with loc/scale support implicitly assumed as 0/1).\n",
        "    \"\"\"\n",
        "    beta_pdf_id = beta_pdf(s, alpha_id, beta_id)\n",
        "    beta_pdf_ood = beta_pdf(s, alpha_ood, beta_ood)\n",
        "    numerator = beta_pdf_id * pi\n",
        "    denominator = numerator + beta_pdf_ood * (1 - pi)\n",
        "    p_id = numerator / (denominator + 1e-8)\n",
        "    return p_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eT1rUk3WJ_c2"
      },
      "outputs": [],
      "source": [
        "\"this function has been tested\"\n",
        "class SelfSupervisionLoss(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_f, out_f, bias=False)\n",
        "\n",
        "    def forward(self, x_w, x_s):\n",
        "        x_s_proj = self.proj(x_s)\n",
        "        x_w = x_w.detach()\n",
        "        dot_product = torch.sum(x_s_proj * x_w, dim=1)\n",
        "        norm_product = torch.norm(x_s_proj, dim=1) * torch.norm(x_w, dim=1)\n",
        "        cosine_sim = dot_product / (norm_product + 1e-8)\n",
        "        return -cosine_sim.mean()\n",
        "\n",
        "\"Can't this be negative??\"\n",
        "\"Though i did test this..\"\n",
        "class SubspaceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, m_id, m_ood, s_z):\n",
        "        m_id, m_ood = m_id.to(dtype=float), m_ood.to(dtype=float)\n",
        "        return torch.mean((m_ood - m_id) * s_z)\n",
        "\n",
        "\"This function has been tested\"\n",
        "\n",
        "class SemiSupervisedLoss(nn.Module):\n",
        "    def __init__(self, threshold):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self,y_pred, y_true, mask_id):\n",
        "        \"\"\"\n",
        "        logits of model on weakly augmented data: y_true\n",
        "        logits of model on strongly augmented data: y_pred\n",
        "        boolean tensors for ID/OOD classification: mask_id\n",
        "        \"\"\"\n",
        "        y_true = y_true.detach()\n",
        "        batch_size = y_pred.size(0)\n",
        "        entropy = F.cross_entropy(y_pred, torch.argmax(y_true, dim=1), reduction=\"none\") # input logits, and true labels\n",
        "        y_prob_true = F.softmax(y_true, dim=1)\n",
        "        sample_id = torch.logical_and(torch.max(y_prob_true, dim=1)[0] >= self.threshold, (mask_id == 1))\n",
        "        return (torch.sum(entropy[sample_id]))/batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vrYn1OMOKC0M"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "num_epoch = 10\n",
        "alpha_id, beta_id = torch.tensor(10, device=device),torch.tensor(2, device=device)\n",
        "alpha_ood, beta_ood = torch.tensor(2, device=device), torch.tensor(10, device=device)\n",
        "warm_up = 5\n",
        "lr = 3e-3\n",
        "backbone.to(device)\n",
        "classifier.to(device)\n",
        "supervised_loss_fn = nn.CrossEntropyLoss()\n",
        "selfsupervised_loss_fn = SelfSupervisionLoss(feature_dim, feature_dim).to(device)\n",
        "subspace_loss_fn = SubspaceLoss().to(device)\n",
        "semisupervised_loss_fn = SemiSupervisedLoss(0.9).to(device)\n",
        "all_params = list(backbone.parameters()) + list(classifier.parameters()) + list(selfsupervised_loss_fn.parameters())\n",
        "optimizer = torch.optim.SGD(all_params, lr=0.01, momentum=0.9, nesterov=True)\n",
        "class_means = torch.zeros((len(ID_CLASSES), feature_dim), requires_grad=False, device=device)\n",
        "class_mean_EMA = 0.2\n",
        "test_accuracy, test_classification_report, test_confusion_matrix, test_auc_roc_score = [], [], [], []\n",
        "num_batches = len(train_labeled_dataloader)\n",
        "batch_means = torch.zeros(len(ID_CLASSES), feature_dim, device=device)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Zuz0WdZINlIz",
        "outputId": "b4fd9b46-5d45-40e0-c275-4a554e7f4c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msujal22514\u001b[0m (\u001b[33msujal22514-indraprastha-institute-of-information-technol\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250414_120129-sgsn89zw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub/runs/sgsn89zw' target=\"_blank\">run_7qmhheu6</a></strong> to <a href='https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub' target=\"_blank\">https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub/runs/sgsn89zw' target=\"_blank\">https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub/runs/sgsn89zw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sujal22514-indraprastha-institute-of-information-technol/Tiny-Imagenet-Prosub/runs/sgsn89zw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c0ff987de50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=\"Tiny-Imagenet-Prosub\",\n",
        "    name=f\"run_{wandb.util.generate_id()}\",\n",
        "    config={\n",
        "        \"epochs\": num_epoch,\n",
        "        \"learning_rate\": lr,\n",
        "        \"warmup_epochs\": warm_up,\n",
        "        \"scheduler\": \"CosineAnnealingLR\",\n",
        "        \"optimizer\": \"SGD w/ Nesterov\",\n",
        "        \"alpha_id\": alpha_id.item(),\n",
        "        \"beta_id\": beta_id.item(),\n",
        "        \"alpha_ood\": alpha_ood.item(),\n",
        "        \"beta_ood\": beta_ood.item()\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Ijj1pXKgZK",
        "outputId": "7999d825-f204-41e0-aa8d-fce39561a623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:33<00:00,  4.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0, acc = 0.4929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:46<00:00,  4.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 1, acc = 0.4922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:58<00:00,  4.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 2, acc = 0.4936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:34<00:00,  4.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 3, acc = 0.4933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:30<00:00,  4.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 4, acc = 0.4932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:32<00:00,  4.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 5, acc = 0.4927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:37<00:00,  4.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 6, acc = 0.4933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:31<00:00,  4.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 7, acc = 0.4915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:: 100%|██████████| 78/78 [05:32<00:00,  4.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 8, acc = 0.4933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training::  58%|█████▊    | 45/78 [03:12<02:17,  4.18s/it]"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epoch):\n",
        "    backbone.train();classifier.train();selfsupervised_loss_fn.train()\n",
        "    for (X_l, y_l), (X_w, X_s) in tqdm(zip(train_labeled_dataloader, train_unlabeled_dataloader), total=num_batches, desc=\"Training:\"):\n",
        "        \"========================Loading inputs to device========================\"\n",
        "        X_l = X_l.to(device)\n",
        "        y_l = y_l.to(device)\n",
        "        X_w = X_w.to(device)\n",
        "        X_s = X_s.to(device)\n",
        "        \"========================Inputs loaded========================\"\n",
        "\n",
        "        \"======================= Processing the labeled dataset =======================\"\n",
        "        Z_l = backbone(X_l)\n",
        "\n",
        "\n",
        "        \"=====================Calculating labeled subspace score============================\"\n",
        "        y_pred_l = classifier(Z_l)\n",
        "        s_l = subspace_score(Z_l, batch_means.detach())\n",
        "        \"=====================Label subspace score calculated============================\"\n",
        "        \"============================Label data processed ============================ \"\n",
        "\n",
        "        \"======================= Processing the labeled dataset =======================\"\n",
        "        Z_s_u, Z_w_u = backbone(X_w), backbone(X_s)\n",
        "\n",
        "        \" ======================= Calculating subspace score and mask =======================\"\n",
        "        s_u = subspace_score(Z_w_u.detach(), batch_means.detach())\n",
        "        Z_s_u_for_cls = Z_s_u.detach()\n",
        "        Z_w_u_for_cls = Z_w_u.detach()\n",
        "\n",
        "        y_pred_u = classifier(Z_s_u_for_cls)\n",
        "        y_gold_u = classifier(Z_w_u_for_cls)\n",
        "        prob_id_u = get_p_id(s_u, alpha_id, beta_id, alpha_ood, beta_ood) # size should be (Un_labeled_batch_size)\n",
        "        prob_ood_u = 1 - prob_id_u\n",
        "        uniform = torch.rand(unlabeled_batch_size, device=device)\n",
        "        mask_id = (prob_id_u.squeeze(1) >= uniform)\n",
        "        mask_ood = ~mask_id\n",
        "        \" ======================= Calculated subspace score and mask =======================\"\n",
        "\n",
        "        \" ============================Calculating losses ============================\"\n",
        "        loss_selfsupervised = selfsupervised_loss_fn(Z_w_u, Z_s_u)\n",
        "        loss_semi_supervised = semisupervised_loss_fn(y_pred_u, y_gold_u, mask_id)\n",
        "        loss_subspace = subspace_loss_fn(mask_id, mask_ood, s_u)\n",
        "        loss_supervised = supervised_loss_fn(y_pred_l, y_l)\n",
        "        \" ============================Losses Calculated ============================\"\n",
        "\n",
        "        \" ============================ Optimizing the model ============================\"\n",
        "        if epoch < warm_up:\n",
        "            loss = 40*loss_selfsupervised + loss_supervised\n",
        "        else:\n",
        "            loss = 40*loss_selfsupervised + loss_semi_supervised + loss_subspace + loss_supervised\n",
        "        loss.backward()\n",
        "        optimizer.zero_grad()\n",
        "        optimizer.step()\n",
        "        \" ============================ Model optimized ============================\"\n",
        "\n",
        "        \" ======================== Performing IIM Step ======================== \"\n",
        "        alpha_id, alpha_ood, alpha_ood, beta_ood = update_beta_parameters(prob_id_u,prob_ood_u, s_l, s_u ,alpha_id, beta_id, alpha_ood, beta_ood, 0.2)\n",
        "        \" ======================== IIM step done ======================== \"\n",
        "        \"======================= Updating class means =======================\"\n",
        "        batch_means = get_batch_mean(Z_l, y_l, len(ID_CLASSES), feature_dim, batch_size, device)\n",
        "        class_means = class_means*class_mean_EMA + (1 - class_mean_EMA)*batch_means\n",
        "        \"======================= Class means updataed =======================\"\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss_supervised\": loss_supervised.item(),\n",
        "            \"loss_selfsupervised\": loss_selfsupervised.item(),\n",
        "            \"loss_semi_supervised\": loss_semi_supervised.item() if epoch >= warm_up else 0.0,\n",
        "            \"loss_subspace\": loss_subspace.item() if epoch >= warm_up else 0.0,\n",
        "        })\n",
        "\n",
        "    scheduler.step()\n",
        "    backbone.eval();classifier.eval();selfsupervised_loss_fn.eval()\n",
        "    test_predictions,test_targets = [], []\n",
        "    with torch.inference_mode():\n",
        "        for X, y_true in test_labeled_dataloader:\n",
        "            y_true = y_true.to(device)\n",
        "            X = X.to(device)\n",
        "            Z = backbone(X)\n",
        "            y_logits = classifier(Z)\n",
        "            prob_id = get_p_id(Z, alpha_id, beta_id, alpha_ood, beta_ood)\n",
        "            y_softmax = F.softmax(y_logits, dim=1)\n",
        "            y_pred = torch.argmax(y_softmax, dim=1, keepdim=False)\n",
        "            uniform = torch.rand(size=(test_size, ), device=device)\n",
        "            y_pred[(torch.max(y_softmax, dim=1)[0] < uniform)] = -1\n",
        "            test_predictions.extend(y_true.cpu().detach().numpy())\n",
        "            test_targets.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    acc = accuracy_score(test_predictions, test_targets)\n",
        "    print(f\"epoch = {epoch}, acc = {acc:.4f}\")\n",
        "    test_accuracy.append(acc)\n",
        "    test_classification_report.append(classification_report(test_predictions, test_targets, zero_division=0))\n",
        "    test_confusion_matrix.append(confusion_matrix(test_predictions, test_targets))\n",
        "    torch.save(backbone.state_dict(), f\"backbone_epoch_{epoch}.pth\")\n",
        "    torch.save(classifier.state_dict(), f\"classifier_epoch_{epoch}.pth\")\n",
        "    torch.save(selfsupervised_loss_fn.state_dict(), f\"selfsupervised_loss_fn_epoch_{epoch}.pth\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beta_parameters = torch.stack([alpha_id, beta_id, alpha_ood, beta_ood])\n",
        "torch.save(beta_parameters, \"beta_parameters.pth\")\n",
        "torch.save(batch_means, \"batch_means.pth\")"
      ],
      "metadata": {
        "id": "nf1w5udZQGxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "\n",
        "def get_batch_mean(Z, y, num_classes, feature_dim, batch_size, device):\n",
        "    sums = torch.zeros(num_classes, feature_dim, dtype=Z_l.dtype, device=device)\n",
        "    counts = torch.zeros(num_classes, dtype=torch.float, device=device)\n",
        "    sums = sums.index_add(0, y_l, Z_l, alpha=1)\n",
        "    ones = torch.ones(batch_size, dtype=torch.float, device=device)\n",
        "    counts = counts.index_add(0, y_l, ones)\n",
        "    counts[counts == 0] = 1.0\n",
        "    avg_values = sums / counts.unsqueeze(1)\n",
        "    return avg_values\n",
        "\n",
        "\n",
        "def subspace_score(Z, batch_means):\n",
        "    \"\"\"\n",
        "    Z: (batch_size, feature_dim)\n",
        "    batch_means: (num_classes, feature_dim)\n",
        "    Returns:\n",
        "        cosine similarity between Z and its projection on the subspace\n",
        "        spanned by batch_means — shape (batch_size, 1)\n",
        "    \"\"\"\n",
        "    Q, _ = torch.linalg.qr(batch_means.T)\n",
        "    proj_Z = Z @ Q @ Q.T\n",
        "    cos_sim = F.cosine_similarity(Z, proj_Z, dim=1).clamp(0, 1)\n",
        "    return cos_sim.unsqueeze(1)\n",
        "\n",
        "\"Taken from the code given by the authors... \"\n",
        "def beta_pdf(x, alpha, beta, loc=0.0, scale=1.0):\n",
        "    x = (x - loc) / scale\n",
        "    alpha = torch.as_tensor(alpha, dtype=torch.float32, device=x.device)\n",
        "    beta = torch.as_tensor(beta, dtype=torch.float32, device=x.device)\n",
        "    scale = torch.as_tensor(scale, dtype=torch.float32, device=x.device)\n",
        "    def xlogy(a, b):\n",
        "        return torch.where(a == 0, torch.zeros_like(b), a * torch.log(b + 1e-10))\n",
        "    def xlog1py(a, y):\n",
        "        return torch.where(a == 0, torch.zeros_like(y), a * torch.log1p(y + 1e-10))\n",
        "\n",
        "    log_unnormalized = xlogy(alpha - 1.0, x) + xlog1py(beta - 1.0, -x)\n",
        "    log_normalization = torch.lgamma(alpha) + torch.lgamma(beta) - torch.lgamma(alpha + beta)\n",
        "    log_prob = log_unnormalized - log_normalization\n",
        "    log_prob = torch.where((x >= 0) & (x <= 1), log_prob, torch.tensor(float('-inf'), device=x.device))\n",
        "\n",
        "    return torch.exp(log_prob) / scale\n",
        "\n",
        "def update_beta_parameters(w_id, w_ood, s_l, s_u ,alpha_id, beta_id, alpha_ood, beta_ood, l):\n",
        "    # Detaching from computational graph so that it won't cause some bullshit error\n",
        "    w_id = w_id.squeeze(1).detach(); w_ood = w_ood.squeeze(1).detach()\n",
        "    s_l = s_l.squeeze(1).detach(); s_u = s_u.squeeze(1).detach()\n",
        "    nu_id = torch.sum(s_l) + torch.dot(w_id, s_u)/(s_l.size(0) + torch.sum(w_id))\n",
        "    sigma2_id = (torch.sum(s_l - nu_id)**2 + torch.dot(w_id, (s_u - nu_id)**2))/(s_l.size(0) + torch.sum(w_id))\n",
        "\n",
        "    nu_ood = torch.dot(w_ood, s_u)/(torch.sum(w_ood))\n",
        "    sigma2_ood = torch.dot(w_ood, (s_u - nu_id)**2)/((torch.sum(w_ood)))\n",
        "\n",
        "    _alpha_id = nu_id*((nu_id*(1-nu_id))/sigma2_id - 1)\n",
        "    _alpha_ood = nu_ood*((nu_ood*(1-nu_ood))/sigma2_ood - 1)\n",
        "    _beta_id = (1 - nu_id)*((nu_id*(1-nu_id))/sigma2_id - 1)\n",
        "    _beta_ood = (1 - nu_ood)*((nu_ood*(1-nu_ood))/sigma2_ood - 1)\n",
        "\n",
        "    return alpha_id*l + (1 - l)*_alpha_id, beta_id*l + (1 - l)*_beta_id, alpha_ood*l + (1 - l)*_alpha_ood, beta_ood*l + (1 - l)*_beta_ood\n",
        "\n",
        "def get_p_id(s, alpha_id, beta_id, alpha_ood, beta_ood, pi=1.0):\n",
        "    \"\"\"\n",
        "    Compute the ID probability using Beta PDFs instead of torch.distributions.Beta,\n",
        "    following the formulation in the paper (with loc/scale support implicitly assumed as 0/1).\n",
        "    \"\"\"\n",
        "    beta_pdf_id = beta_pdf(s, alpha_id, beta_id)\n",
        "    beta_pdf_ood = beta_pdf(s, alpha_ood, beta_ood)\n",
        "    numerator = beta_pdf_id * pi\n",
        "    denominator = numerator + beta_pdf_ood * (1 - pi)\n",
        "    p_id = numerator / (denominator + 1e-8)\n",
        "    return p_id\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(in_f, out_f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "class InferenceModelImage:\n",
        "    def __init__(self, backbone_pth, classifier_pth, batch_mean_pth, beta_parameters_pth):\n",
        "        self.feature_dim = 200\n",
        "        self.num_classes = 100\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.backbone = timm.create_model('resnet34', pretrained=True)\n",
        "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, self.feature_dim)\n",
        "        self.backbone.load_state_dict(torch.load(backbone_pth, map_location=self.device))\n",
        "        self.backbone = self.backbone.to(self.device)\n",
        "        self.backbone.eval()\n",
        "\n",
        "        self.classifier = Classifier(self.feature_dim, self.num_classes)\n",
        "        self.classifier.load_state_dict(torch.load(classifier_pth, map_location=self.device))\n",
        "        self.classifier = self.classifier.to(self.device)\n",
        "        self.classifier.eval()\n",
        "\n",
        "        self.batch_means = torch.load(batch_mean_pth, map_location=self.device).to(self.device)\n",
        "        beta_parameters = torch.load(beta_parameters_pth, map_location=self.device).to(self.device)\n",
        "        self.alpha_id, self.beta_id, self.alpha_ood, self.beta_ood = beta_parameters.chunk(4)\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "\n",
        "    def _preprocess_image(self, img_path):\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "        return tensor\n",
        "\n",
        "    def __call__(self, image_path):\n",
        "        x = self._preprocess_image(image_path)\n",
        "        Z = self.backbone(x)\n",
        "        s_score = subspace_score(Z, self.batch_means)\n",
        "        p_id = get_p_id(\n",
        "            s_score,\n",
        "            self.alpha_id.to(self.device),\n",
        "            self.beta_id.to(self.device),\n",
        "            self.alpha_ood.to(self.device),\n",
        "            self.beta_ood.to(self.device)\n",
        "        )\n",
        "        if p_id[0] < torch.rand(1, device=self.device):\n",
        "            return -1\n",
        "        y = self.classifier(Z)\n",
        "        return torch.argmax(y, dim=1)\n"
      ],
      "metadata": {
        "id": "kIKZNwDtMnGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone_pth = \"backbone_fsd_kaggle.pth\"\n",
        "classifier_pth = \"classifier_epoch_fsd_kaggle.pth\"\n",
        "beta_parameters_pth = \"beta_parameters_fsd_kaggle.pth\"\n",
        "batch_mean_pth = \"batch_means_fsd_kaggle.pth\"\n",
        "\n",
        "test_inf = InferenceModelImage(backbone_pth, classifier_pth, batch_mean_pth, beta_parameters_pth)\n",
        "print(test_inf(\"path\"))"
      ],
      "metadata": {
        "id": "8HETlOEkNn2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df00f34e3b68417d9e719f8e1c234018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5de9954b209d428691e0570ab50405cf",
              "IPY_MODEL_70000964998e4280914b7952d2023a6c",
              "IPY_MODEL_e85d72cb905b42808d964ffafec45746"
            ],
            "layout": "IPY_MODEL_469c4128f79b45dcb5d1e1cfe4db6510"
          }
        },
        "5de9954b209d428691e0570ab50405cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57201124bf684033a9140e48e2f36de6",
            "placeholder": "​",
            "style": "IPY_MODEL_3ecfb767a6554ad09e3b14c5869c078f",
            "value": "model.safetensors: 100%"
          }
        },
        "70000964998e4280914b7952d2023a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de810702cdd94a218509e4ced6965bd5",
            "max": 87278522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27e67008b05a486887639009ad2b3c1a",
            "value": 87278522
          }
        },
        "e85d72cb905b42808d964ffafec45746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3824b1fb8c54a749ef8ab5f0e7676d6",
            "placeholder": "​",
            "style": "IPY_MODEL_03af46f2574f453f9cff091041cc7627",
            "value": " 87.3M/87.3M [00:00&lt;00:00, 145MB/s]"
          }
        },
        "469c4128f79b45dcb5d1e1cfe4db6510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57201124bf684033a9140e48e2f36de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecfb767a6554ad09e3b14c5869c078f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de810702cdd94a218509e4ced6965bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e67008b05a486887639009ad2b3c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3824b1fb8c54a749ef8ab5f0e7676d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03af46f2574f453f9cff091041cc7627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}